#!/usr/bin/env python3
"""
ìŠ¤íŠ¸ë¦¬ë° ë™ì‹œì„± í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ì—¬ëŸ¬ í´ë¼ì´ì–¸íŠ¸ê°€ ë™ì‹œì— ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ì„ ë³´ë‚´ì„œ ë¸”ë¡œí‚¹ ì—¬ë¶€ë¥¼ í™•ì¸
"""

import asyncio
import aiohttp
import json
import time
from datetime import datetime

SERVER_URL = "http://localhost:5001"

# í…ŒìŠ¤íŠ¸ìš© ê°„ë‹¨í•œ ì›Œí¬í”Œë¡œìš° ì •ì˜
TEST_WORKFLOW = {
    "workflow": {
        "nodes": [
            {
                "id": "input-1",
                "type": "input-node",
                "position": {"x": 100, "y": 100},
                "content": "í…ŒìŠ¤íŠ¸ ì…ë ¥ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.",
                "model_type": None,
                "llm_provider": None,
                "prompt": None,
                "knowledge_base": None,
                "search_intensity": None,
                "rerank_provider": None,
                "rerank_model": None,
                "output": None,
                "executed": False,
                "error": None
            },
            {
                "id": "generation-1",
                "type": "generation-node",
                "position": {"x": 300, "y": 100},
                "content": None,
                "model_type": "gemini-1.5-flash",
                "llm_provider": "google",
                "prompt": "ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”: {input}",
                "knowledge_base": None,
                "search_intensity": None,
                "rerank_provider": None,
                "rerank_model": None,
                "output": None,
                "executed": False,
                "error": None
            },
            {
                "id": "output-1",
                "type": "output-node",
                "position": {"x": 500, "y": 100},
                "content": "ìµœì¢… ê²°ê³¼",
                "model_type": None,
                "llm_provider": None,
                "prompt": None,
                "knowledge_base": None,
                "search_intensity": None,
                "rerank_provider": None,
                "rerank_model": None,
                "output": None,
                "executed": False,
                "error": None
            }
        ],
        "edges": [
            {"id": "edge-1", "source": "input-1", "target": "generation-1"},
            {"id": "edge-2", "source": "generation-1", "target": "output-1"}
        ]
    }
}

async def streaming_client(client_id: int, session: aiohttp.ClientSession):
    """ë‹¨ì¼ í´ë¼ì´ì–¸íŠ¸ ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸"""
    start_time = time.time()
    print(f"[Client {client_id}] {datetime.now().strftime('%H:%M:%S.%f')[:-3]} - ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘")
    
    try:
        async with session.post(
            f"{SERVER_URL}/execute-workflow-stream",
            json=TEST_WORKFLOW,
            headers={"Content-Type": "application/json"}
        ) as response:
            
            if response.status != 200:
                print(f"[Client {client_id}] HTTP ì˜¤ë¥˜: {response.status}")
                return False, time.time() - start_time
            
            # SSE ìŠ¤íŠ¸ë¦¼ ì½ê¸°
            chunk_count = 0
            async for line in response.content:
                line_str = line.decode('utf-8').strip()
                if line_str.startswith('data: '):
                    try:
                        data = json.loads(line_str[6:])
                        chunk_count += 1
                        
                        # ì£¼ìš” ì´ë²¤íŠ¸ë§Œ ë¡œê·¸
                        if data.get('type') in ['start', 'node_start', 'complete', 'error']:
                            timestamp = datetime.now().strftime('%H:%M:%S.%f')[:-3]
                            print(f"[Client {client_id}] {timestamp} - {data.get('type')}: {data.get('message', '')}")
                        
                        # ì™„ë£Œ ë˜ëŠ” ì—ëŸ¬ ì‹œ ì¢…ë£Œ
                        if data.get('type') in ['complete', 'error']:
                            elapsed = time.time() - start_time
                            print(f"[Client {client_id}] {datetime.now().strftime('%H:%M:%S.%f')[:-3]} - ì™„ë£Œ ({elapsed:.2f}ì´ˆ, {chunk_count}ê°œ ì²­í¬)")
                            return True, elapsed
                            
                    except json.JSONDecodeError:
                        continue
            
            elapsed = time.time() - start_time
            print(f"[Client {client_id}] ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ ({elapsed:.2f}ì´ˆ, {chunk_count}ê°œ ì²­í¬)")
            return True, elapsed
            
    except Exception as e:
        elapsed = time.time() - start_time
        print(f"[Client {client_id}] ì—ëŸ¬: {e} ({elapsed:.2f}ì´ˆ)")
        return False, elapsed

async def test_concurrent_streaming(num_clients: int = 3):
    """ë™ì‹œ ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸš€ {num_clients}ê°œ í´ë¼ì´ì–¸íŠ¸ ë™ì‹œ ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print(f"ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%H:%M:%S')}")
    print("-" * 60)
    
    # ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ë¥¼ ë™ì‹œì— ì‹œì‘
    connector = aiohttp.TCPConnector(limit=100, limit_per_host=50)
    timeout = aiohttp.ClientTimeout(total=120)  # 2ë¶„ íƒ€ì„ì•„ì›ƒ
    
    async with aiohttp.ClientSession(
        connector=connector, 
        timeout=timeout
    ) as session:
        
        # ë™ì‹œ ì‹¤í–‰
        tasks = [
            streaming_client(i, session) 
            for i in range(1, num_clients + 1)
        ]
        
        start_time = time.time()
        results = await asyncio.gather(*tasks, return_exceptions=True)
        total_time = time.time() - start_time
        
        print("-" * 60)
        print(f"ì „ì²´ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {total_time:.2f}ì´ˆ")
        
        # ê²°ê³¼ ë¶„ì„
        successful = 0
        failed = 0
        times = []
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                print(f"Client {i+1}: ì˜ˆì™¸ ë°œìƒ - {result}")
                failed += 1
            else:
                success, elapsed = result
                if success:
                    successful += 1
                    times.append(elapsed)
                else:
                    failed += 1
        
        print(f"\nğŸ“Š ê²°ê³¼ ìš”ì•½:")
        print(f"- ì„±ê³µ: {successful}/{num_clients}")
        print(f"- ì‹¤íŒ¨: {failed}/{num_clients}")
        
        if times:
            avg_time = sum(times) / len(times)
            min_time = min(times)
            max_time = max(times)
            print(f"- í‰ê·  ì‹¤í–‰ ì‹œê°„: {avg_time:.2f}ì´ˆ")
            print(f"- ìµœë‹¨ ì‹¤í–‰ ì‹œê°„: {min_time:.2f}ì´ˆ")
            print(f"- ìµœì¥ ì‹¤í–‰ ì‹œê°„: {max_time:.2f}ì´ˆ")
            print(f"- ì‹œê°„ ì°¨ì´: {max_time - min_time:.2f}ì´ˆ")
            
            # ë¸”ë¡œí‚¹ ì—¬ë¶€ íŒë‹¨
            if max_time - min_time > 5.0:  # 5ì´ˆ ì´ìƒ ì°¨ì´ë‚˜ë©´ ë¸”ë¡œí‚¹ ì˜ì‹¬
                print("âš ï¸  í´ë¼ì´ì–¸íŠ¸ ê°„ ì‹¤í–‰ ì‹œê°„ ì°¨ì´ê°€ í½ë‹ˆë‹¤. ë¸”ë¡œí‚¹ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            else:
                print("âœ… í´ë¼ì´ì–¸íŠ¸ë“¤ì´ ë¹„ìŠ·í•œ ì‹œê°„ì— ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë¸”ë¡œí‚¹ì´ í•´ê²°ëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤.")

async def test_api_response_times():
    """ê¸°ë³¸ API ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” API ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸")
    print("-" * 40)
    
    async with aiohttp.ClientSession() as session:
        # í—¬ìŠ¤ì²´í¬
        start = time.time()
        async with session.get(f"{SERVER_URL}/") as response:
            if response.status == 200:
                health_time = time.time() - start
                print(f"í—¬ìŠ¤ì²´í¬: {health_time:.3f}ì´ˆ")
        
        # ì§€ì‹ë² ì´ìŠ¤ ëª©ë¡
        start = time.time()
        async with session.get(f"{SERVER_URL}/knowledge-bases") as response:
            if response.status == 200:
                kb_time = time.time() - start
                print(f"ì§€ì‹ë² ì´ìŠ¤ ëª©ë¡: {kb_time:.3f}ì´ˆ")
        
        # Google ëª¨ë¸ ëª©ë¡
        start = time.time()
        async with session.get(f"{SERVER_URL}/available-models/google") as response:
            if response.status == 200:
                models_time = time.time() - start
                print(f"Google ëª¨ë¸ ëª©ë¡: {models_time:.3f}ì´ˆ")

if __name__ == "__main__":
    print("ğŸ§ª MultiModelGenerator ìŠ¤íŠ¸ë¦¬ë° ë™ì‹œì„± í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # ê¸°ë³¸ API ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸
    asyncio.run(test_api_response_times())
    
    # ìŠ¤íŠ¸ë¦¬ë° ë™ì‹œì„± í…ŒìŠ¤íŠ¸ (3ê°œ í´ë¼ì´ì–¸íŠ¸)
    asyncio.run(test_concurrent_streaming(3))
    
    print("\nğŸ¯ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")