"""
Layerë³„ ì‹¤í–‰ ë¡œì§ì„ ë‹´ë‹¹í•˜ëŠ” ëª¨ë“ˆ
"""
import time
import logging
import re
from typing import List, Tuple, Dict, Any

from ..core.layer_engine import LayerEngine
from ..core.models import NodeConfig, NodeOutput
from ..services.vector_store import VectorStore

logger = logging.getLogger(__name__)

def parse_structured_output(content: str) -> Tuple[str, str]:
    """
    LLM ì¶œë ¥ì—ì„œ JSON êµ¬ì¡°ë¥¼ íŒŒì‹±í•˜ì—¬ general_outputê³¼ forward_dataë¥¼ ì¶”ì¶œ
    ê°•í™”ëœ íŒŒì‹± ë¡œì§ìœ¼ë¡œ ë‹¤ì–‘í•œ JSON í˜•íƒœë¥¼ ì²˜ë¦¬
    """
    import json
    import re
    
    if not content or not content.strip():
        print("âŒ Content is empty or None")
        return "", ""
    
    print(f"ğŸ” Starting to parse content (length: {len(content)})")
    print(f"ğŸ” First 500 chars: {content[:500]}")
    logger.info("êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì‹± ì‹œì‘")
    
    try:
        # 1. ë‹¤ì–‘í•œ ì½”ë“œ ë¸”ë¡ íŒ¨í„´ ì‹œë„
        code_block_patterns = [
            r'```json\s*(.*?)\s*```',  # ```json ... ```
            r'```JSON\s*(.*?)\s*```',  # ```JSON ... ```
            r'```\s*(.*?)\s*```',      # ``` ... ```
            r'`json\s*(.*?)\s*`',      # `json ... `
            r'`(.*?)`'                 # ` ... `
        ]
        
        for pattern in code_block_patterns:
            matches = re.finditer(pattern, content, re.DOTALL | re.IGNORECASE)
            for match in matches:
                json_str = match.group(1).strip()
                
                if not json_str:
                    continue
                
                print(f"ğŸ“ Found code block: {json_str[:300]}...")
                
                # JSON ë¬¸ìì—´ ì •ë¦¬
                json_str = json_str.replace('\\\\\\', '\\')  # ì‚¼ì¤‘ ë°±ìŠ¬ë˜ì‹œ ì •ë¦¬
                json_str = json_str.replace('\\\\', '\\')    # ì´ì¤‘ ë°±ìŠ¬ë˜ì‹œ ì •ë¦¬
                json_str = re.sub(r'^\s*json\s*', '', json_str, flags=re.IGNORECASE)  # ì‹œì‘ json í‚¤ì›Œë“œ ì œê±°
                json_str = re.sub(r'\s*json\s*$', '', json_str, flags=re.IGNORECASE)  # ë json í‚¤ì›Œë“œ ì œê±°
                json_str = re.sub(r'^\s*json\s*$', '', json_str, flags=re.MULTILINE | re.IGNORECASE)  # ë‹¨ë… json ë¼ì¸ ì œê±°
                
                # JSON ê°ì²´ ì¶”ì¶œ
                first_brace = json_str.find('{')
                last_brace = json_str.rfind('}')
                
                if first_brace != -1 and last_brace != -1 and last_brace > first_brace:
                    json_str = json_str[first_brace:last_brace + 1]
                    
                    # ë§ˆì§€ë§‰ ì½¤ë§ˆ ì œê±° (ì˜ëª»ëœ JSON ìˆ˜ì •)
                    json_str = re.sub(r',(\s*[}\]])', r'\1', json_str)
                    
                    try:
                        parsed_json = json.loads(json_str)
                        print(f"âœ… Successfully parsed JSON from code block: {type(parsed_json)}")
                        
                        general_output = parsed_json.get("general_output", "")
                        forward_data = parsed_json.get("forward_data", "")
                        
                        # ë¬¸ìì—´ ì •ë¦¬
                        if general_output:
                            general_output = general_output.replace("\\n", "\n").replace('\\"', '"').replace('\\\\', '\\')
                        if forward_data:
                            forward_data = forward_data.replace("\\n", "\n").replace('\\"', '"').replace('\\\\', '\\')
                        
                        print(f"ğŸ“¦ Extracted general_output length: {len(general_output)}")
                        print(f"ğŸ“¦ Extracted forward_data length: {len(forward_data)}")
                        print(f"ğŸ“¦ forward_data preview: {forward_data[:200] if forward_data else 'EMPTY'}")
                        
                        logger.info(f"JSON íŒŒì‹± ì„±ê³µ - general_output: {len(general_output)}ì, forward_data: {len(forward_data)}ì")
                        return general_output, forward_data
                        
                    except json.JSONDecodeError as e:
                        print(f"âŒ JSON decode error in code block: {e}")
                        continue
        
        # 2. ì „ì²´ ë‚´ìš©ì—ì„œ JSON ê°ì²´ ì°¾ê¸° (ì½”ë“œ ë¸”ë¡ ì—†ì´)
        print("ğŸ” No code block found, trying to find JSON object in content")
        
        # ë‹¤ì–‘í•œ JSON íŒ¨í„´ ì‹œë„
        json_patterns = [
            r'\{\s*"general_output".*?"forward_data".*?\}',  # general_outputê³¼ forward_data í¬í•¨
            r'\{\s*"forward_data".*?"general_output".*?\}',  # ìˆœì„œ ë°”ë€ ê²½ìš°
            r'\{.*?"general_output".*?\}',                   # general_outputë§Œ ìˆëŠ” ê²½ìš°
            r'\{.*?"forward_data".*?\}',                     # forward_dataë§Œ ìˆëŠ” ê²½ìš°
            r'\{.*?\}'                                       # ëª¨ë“  JSON ê°ì²´
        ]
        
        for pattern in json_patterns:
            matches = re.finditer(pattern, content, re.DOTALL)
            for match in matches:
                json_str = match.group(0).strip()
                
                # JSON ì •ë¦¬
                json_str = json_str.replace('\\\\\\', '\\').replace('\\\\', '\\')
                json_str = re.sub(r',(\s*[}\]])', r'\1', json_str)  # ë§ˆì§€ë§‰ ì½¤ë§ˆ ì œê±°
                
                print(f"ğŸ“ Found JSON object: {json_str[:300]}...")
                
                try:
                    parsed_json = json.loads(json_str)
                    general_output = parsed_json.get("general_output", "")
                    forward_data = parsed_json.get("forward_data", "")
                    
                    # ë¬¸ìì—´ ì •ë¦¬
                    if general_output:
                        general_output = general_output.replace("\\n", "\n").replace('\\"', '"').replace('\\\\', '\\')
                    if forward_data:
                        forward_data = forward_data.replace("\\n", "\n").replace('\\"', '"').replace('\\\\', '\\')
                    
                    print(f"âœ… Successfully parsed JSON object")
                    print(f"ğŸ“¦ general_output length: {len(general_output)}")
                    print(f"ğŸ“¦ forward_data length: {len(forward_data)}")
                    
                    return general_output, forward_data
                    
                except json.JSONDecodeError as e:
                    print(f"âŒ JSON decode error in object: {e}")
                    continue
        
        # 3. ì •ê·œì‹ìœ¼ë¡œ í‚¤-ê°’ ìŒ ì§ì ‘ ì¶”ì¶œ
        print("ğŸ” Trying regex extraction of key-value pairs")
        
        general_output_match = re.search(r'"general_output"\s*:\s*"((?:[^"\\]|\\[\s\S])*)"', content, re.DOTALL)
        forward_data_match = re.search(r'"forward_data"\s*:\s*"((?:[^"\\]|\\[\s\S])*)"', content, re.DOTALL)
        
        if general_output_match or forward_data_match:
            general_output = general_output_match.group(1) if general_output_match else ""
            forward_data = forward_data_match.group(1) if forward_data_match else ""
            
            # ë¬¸ìì—´ ì •ë¦¬
            if general_output:
                general_output = general_output.replace("\\n", "\n").replace('\\"', '"').replace('\\\\', '\\')
            if forward_data:
                forward_data = forward_data.replace("\\n", "\n").replace('\\"', '"').replace('\\\\', '\\')
            
            print(f"âœ… Successfully extracted via regex")
            print(f"ğŸ“¦ general_output length: {len(general_output)}")
            print(f"ğŸ“¦ forward_data length: {len(forward_data)}")
            
            return general_output, forward_data
        
        # 4. ì „ì²´ ë‚´ìš©ì´ JSONì¸ì§€ ë§ˆì§€ë§‰ í™•ì¸
        trimmed_content = content.strip()
        
        # "json" í‚¤ì›Œë“œ ì œê±°
        trimmed_content = re.sub(r'^\s*json\s*', '', trimmed_content, flags=re.IGNORECASE)
        trimmed_content = re.sub(r'\s*json\s*$', '', trimmed_content, flags=re.IGNORECASE)
        trimmed_content = trimmed_content.replace('\\\\\\', '\\').replace('\\\\', '\\')
        
        if trimmed_content.startswith('{') and trimmed_content.endswith('}'):
            print("ğŸ” Trying to parse entire content as JSON")
            
            # ë§ˆì§€ë§‰ ì½¤ë§ˆ ì œê±°
            trimmed_content = re.sub(r',(\s*[}\]])', r'\1', trimmed_content)
            
            try:
                parsed_json = json.loads(trimmed_content)
                general_output = parsed_json.get("general_output", "")
                forward_data = parsed_json.get("forward_data", "")
                
                # ë¬¸ìì—´ ì •ë¦¬
                if general_output:
                    general_output = general_output.replace("\\n", "\n").replace('\\"', '"').replace('\\\\', '\\')
                if forward_data:
                    forward_data = forward_data.replace("\\n", "\n").replace('\\"', '"').replace('\\\\', '\\')
                
                print(f"âœ… JSON ì§ì ‘ íŒŒì‹± ì„±ê³µ")
                return general_output, forward_data
            except json.JSONDecodeError as e:
                print(f"âŒ Final JSON parse failed: {e}")
        
        # 5. JSONì´ ì•„ë‹Œ ê²½ìš° ì „ì²´ ë‚´ìš©ì„ general_outputìœ¼ë¡œ ì²˜ë¦¬
        print("âŒ No valid JSON found. Using entire content as general_output")
        logger.warning("JSON ë¸”ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ. ì „ì²´ ë‚´ìš©ì„ general_outputìœ¼ë¡œ ì²˜ë¦¬")
        return content, ""
            
    except Exception as e:
        print(f"âŒ Unexpected error in parse_structured_output: {e}")
        logger.error(f"êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì‹± ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        return content, ""


def execute_generation_layer(nodes: List[NodeConfig], layer_input: str, context_chunks: List[str]) -> Dict[str, Any]:
    """
    Generation Layer ì‹¤í–‰
    Returns: {
        "node1": node1ì˜ general_output,
        "node2": node2ì˜ general_output,
        ...
        "forward_data": ëª¨ë“  ë…¸ë“œì˜ forward_dataë¥¼ appendí•œ ê²°ê³¼
    }
    """
    logger.info(f"Generation Layer ì‹¤í–‰ ì‹œì‘: {len(nodes)}ê°œ ë…¸ë“œ")
    
    engine = LayerEngine()
    result = {}
    forward_data_list = []
    
    # ê° ë…¸ë“œ ë³‘ë ¬ ì‹¤í–‰
    for node in nodes:
        try:
            node_output = engine.execute_node(node, layer_input, context_chunks)
            
            # êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì‹±
            general_output, forward_data = parse_structured_output(node_output.requirements)
            
            # ë…¸ë“œë³„ general_output ì €ì¥
            result[f"node{node.id}"] = general_output
            
            # forward_data ìˆ˜ì§‘ (append ë°©ì‹)
            if forward_data.strip():
                forward_data_list.append(forward_data.strip())
                
            logger.info(f"ë…¸ë“œ {node.id} ì‹¤í–‰ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ë…¸ë“œ {node.id} ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
            result[f"node{node.id}"] = f"ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}"
    
    # ëª¨ë“  forward_dataë¥¼ appendí•˜ì—¬ ê²°í•©
    result["forward_data"] = "\n\n".join(forward_data_list)
    
    logger.info(f"Generation Layer ì™„ë£Œ: {len(forward_data_list)}ê°œ ë…¸ë“œ ê²°ê³¼ ê²°í•©")
    return result


def execute_ensemble_layer(nodes: List[NodeConfig], layer_input: str, context_chunks: List[str]) -> Dict[str, Any]:
    """
    Ensemble Layer ì‹¤í–‰
    Returns: {
        "node1": node1ì˜ general_output,
        "node2": node2ì˜ general_output,
        ...
        "forward_data": ëª¨ë“  ë…¸ë“œì˜ forward_dataë¥¼ appendí•œ ê²°ê³¼
    }
    """
    logger.info(f"Ensemble Layer ì‹¤í–‰ ì‹œì‘: {len(nodes)}ê°œ ë…¸ë“œ")
    
    engine = LayerEngine()
    result = {}
    forward_data_list = []
    
    # ê° ë…¸ë“œ ë³‘ë ¬ ì‹¤í–‰
    for node in nodes:
        try:
            node_output = engine.execute_node(node, layer_input, context_chunks)
            
            # êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì‹±
            general_output, forward_data = parse_structured_output(node_output.requirements)
            
            # ë…¸ë“œë³„ general_output ì €ì¥
            result[f"node{node.id}"] = general_output
            
            # forward_data ìˆ˜ì§‘ (append ë°©ì‹)
            if forward_data.strip():
                forward_data_list.append(forward_data.strip())
                
            logger.info(f"ë…¸ë“œ {node.id} ì‹¤í–‰ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ë…¸ë“œ {node.id} ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
            result[f"node{node.id}"] = f"ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}"
    
    # ëª¨ë“  forward_dataë¥¼ appendí•˜ì—¬ ê²°í•©
    result["forward_data"] = "\n\n".join(forward_data_list)
    
    logger.info(f"Ensemble Layer ì™„ë£Œ: {len(forward_data_list)}ê°œ ë…¸ë“œ ê²°ê³¼ ê²°í•©")
    return result


def execute_validation_layer(nodes: List[NodeConfig], layer_input: str, context_chunks: List[str]) -> Dict[str, Any]:
    """
    Validation Layer ì‹¤í–‰
    Returns: {
        "node1": node1ì˜ general_output,
        "node2": node2ì˜ general_output,
        ...
        "forward_data": ë§ˆì§€ë§‰ ë…¸ë“œì˜ forward_data (ë®ì–´ì“°ê¸° ë°©ì‹)
    }
    """
    print(f"ğŸ” Validation Layer Input: {layer_input[:200] if layer_input else 'EMPTY'}")
    logger.info(f"Validation Layer ì‹¤í–‰ ì‹œì‘: {len(nodes)}ê°œ ë…¸ë“œ")
    
    engine = LayerEngine()
    result = {}
    final_forward_data = ""
    
    # ê° ë…¸ë“œ ìˆœì°¨ ì‹¤í–‰ (Validationì€ ìˆœì„œê°€ ì¤‘ìš”í•  ìˆ˜ ìˆìŒ)
    for node in nodes:
        try:
            print(f"ğŸš€ Executing Validation node {node.id}")
            node_output = engine.execute_node(node, layer_input, context_chunks)
            print(f"ğŸ“ Raw node output length: {len(node_output.requirements)}")
            print(f"ğŸ“ Raw node output preview: {node_output.requirements[:300]}")
            
            # êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì‹±
            general_output, forward_data = parse_structured_output(node_output.requirements)
            print(f"ğŸ“¦ Parsed general_output length: {len(general_output)}")
            print(f"ğŸ“¦ Parsed forward_data length: {len(forward_data)}")
            print(f"ğŸ“¦ forward_data preview: {forward_data[:100] if forward_data else 'EMPTY'}")
            
            # ë…¸ë“œë³„ general_output ì €ì¥
            result[f"node{node.id}"] = general_output
            
            # forward_data ë®ì–´ì“°ê¸° (ë§ˆì§€ë§‰ ë…¸ë“œ ê²°ê³¼ë§Œ ë‚¨ê¹€)
            if forward_data.strip():
                final_forward_data = forward_data.strip()
                print(f"âœ… Updated final_forward_data from node {node.id}")
                
            logger.info(f"ë…¸ë“œ {node.id} ì‹¤í–‰ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ Node {node.id} execution failed: {str(e)}")
            logger.error(f"ë…¸ë“œ {node.id} ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
            result[f"node{node.id}"] = f"ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}"
    
    # ë§ˆì§€ë§‰ ë…¸ë“œì˜ forward_dataë§Œ ì‚¬ìš©
    result["forward_data"] = final_forward_data
    print(f"ğŸ¯ Final result forward_data length: {len(final_forward_data)}")
    print(f"ğŸ¯ Final result keys: {list(result.keys())}")
    
    logger.info(f"Validation Layer ì™„ë£Œ: ìµœì¢… forward_data ê¸¸ì´ {len(final_forward_data)}")
    return result


class ValidationLayerExecutor:
    """Validation Layer ì‹¤í–‰ì„ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.engine = LayerEngine()
    
    def enhance_context_for_validation(self, layer_input: str, knowledge_base: str, 
                                     existing_chunks: List[str], top_k: int = 10) -> List[str]:
        """
        Validationì„ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ í™•ì¥
        """
        try:
            logger.info(f"ğŸ” Validation Layer ì»¨í…ìŠ¤íŠ¸ í™•ì¥ ì‹œì‘ - ê¸°ì¡´ ì²­í¬: {len(existing_chunks)}ê°œ")
            
            vector_store = VectorStore(knowledge_base)
            
            # ì…ë ¥ ë°ì´í„°ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œí•˜ì—¬ ì¶”ê°€ ê²€ìƒ‰
            requirement_texts = re.findall(r'\|\s*[^|]+\s*\|\s*([^|]+)\s*\|', layer_input)
            search_terms = []
            
            logger.info(f"ì…ë ¥ ë°ì´í„°ì—ì„œ {len(requirement_texts)}ê°œ ìš”êµ¬ì‚¬í•­ í…ìŠ¤íŠ¸ ì¶”ì¶œ")
            
            # ìš”êµ¬ì‚¬í•­ì—ì„œ ì¤‘ìš”í•œ í‚¤ì›Œë“œë“¤ ì¶”ì¶œ
            for req_text in requirement_texts[:3]:  # ì²˜ìŒ 3ê°œ ìš”êµ¬ì‚¬í•­ë§Œ ì‚¬ìš©
                if req_text.strip() and len(req_text.strip()) > 10:
                    search_term = req_text.strip()[:50]  # ì²˜ìŒ 50ìë§Œ ì‚¬ìš©
                    search_terms.append(search_term)
                    logger.info(f"ê²€ìƒ‰ì–´ ì¶”ê°€: {search_term}")
            
            # ê° ê²€ìƒ‰ì–´ë¡œ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
            all_chunks = set(existing_chunks)
            for i, term in enumerate(search_terms):
                if term:
                    logger.info(f"ê²€ìƒ‰ì–´ {i+1}/{len(search_terms)} ì‹¤í–‰: '{term[:30]}...'")
                    chunks = vector_store.search_similar_chunks(term, top_k=top_k)
                    chunk_count_before = len(all_chunks)
                    all_chunks.update(chunks)
                    logger.info(f"ìƒˆë¡œ ì¶”ê°€ëœ ì²­í¬: {len(all_chunks) - chunk_count_before}ê°œ")
            
            enhanced_chunks = list(all_chunks)[:20]  # ìµœëŒ€ 20ê°œ ì²­í¬
            logger.info(f"Validationì„ ìœ„í•œ ìµœì¢… ì»¨í…ìŠ¤íŠ¸: {len(enhanced_chunks)}ê°œ ì²­í¬")
            
            return enhanced_chunks
            
        except Exception as e:
            logger.error(f"Validation ì»¨í…ìŠ¤íŠ¸ í™•ì¥ ì‹¤íŒ¨: {e}")
            return existing_chunks
    
    def execute(self, nodes: List[NodeConfig], layer_input: str, context_chunks: List[str]) -> Tuple[List[NodeOutput], List[str], List[Dict]]:
        """
        Validation Layer ì‹¤í–‰ - ìˆœì°¨ì ìœ¼ë¡œ ë…¸ë“œ ì‹¤í–‰í•˜ì—¬ ê²€ì¦ ê³¼ì • ì§„í–‰
        """
        logger.info(f"Validation Layer ì‹¤í–‰ ì‹œì‘: {len(nodes)}ê°œ ë…¸ë“œ")
        
        outputs = []
        failed_nodes = []
        validation_steps = []
        current_input = layer_input
        
        # ë…¸ë“œë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰
        for i, node in enumerate(nodes):
            try:
                logger.info(f"Validation ë…¸ë“œ {i+1}/{len(nodes)} ì‹¤í–‰ ì¤‘: {node.id}")
                
                # ì•ˆì „í•œ ë…¸ë“œ ì‹¤í–‰
                node_output = self.engine.execute_node(node, current_input, context_chunks)
                if not node_output:
                    logger.error(f"ë…¸ë“œ {node.id}ì—ì„œ None ê²°ê³¼ ë°˜í™˜")
                    failed_nodes.append(node.id)
                    continue
                    
                outputs.append(node_output)
                
                # ê²€ì¦ ë‹¨ê³„ ê¸°ë¡
                validation_step = {
                    "step": i + 1,
                    "node_id": node.id,
                    "model_type": getattr(node, 'model_type', 'unknown'),
                    "input": current_input[:200] + "..." if len(current_input) > 200 else current_input,
                    "output": (node_output.requirements[:200] + "..." if len(node_output.requirements) > 200 else node_output.requirements) if hasattr(node_output, 'requirements') and node_output.requirements else "Empty output",
                    "execution_time": getattr(node_output, 'execution_time', 0)
                }
                validation_steps.append(validation_step)
                
                # ë‹¤ìŒ ë…¸ë“œë¥¼ ìœ„í•´ í˜„ì¬ ì¶œë ¥ì„ ì…ë ¥ìœ¼ë¡œ ì„¤ì •
                if hasattr(node_output, 'requirements') and node_output.requirements:
                    current_input = node_output.requirements
                else:
                    logger.warning(f"ë…¸ë“œ {node.id}ì—ì„œ ìœ íš¨í•œ requirements ì¶œë ¥ì´ ì—†ìŒ")
                
                logger.info(f"Validation ë…¸ë“œ {node.id} ì‹¤í–‰ ì™„ë£Œ")
                
            except Exception as e:
                failed_nodes.append(node.id)
                logger.error(f"Validation ë…¸ë“œ {node.id} ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
                logger.error(f"ë…¸ë“œ ì‹¤í–‰ ì˜¤ë¥˜ ìƒì„¸: {repr(e)}")
        
        if not outputs:
            logger.error("ëª¨ë“  Validation ë…¸ë“œ ì‹¤í–‰ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        return outputs, failed_nodes, validation_steps
    
    def combine_results(self, outputs: List[NodeOutput]) -> str:
        """Validation Layer ê²°ê³¼ ê²°í•© - ë§ˆì§€ë§‰ ë…¸ë“œì˜ ì¶œë ¥ì´ ìµœì¢… ê²°ê³¼"""
        if not outputs:
            logger.error("Validation Layer: ê²°í•©í•  ì¶œë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
            return "ëª¨ë“  ë…¸ë“œ ì‹¤í–‰ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
        
        last_output = outputs[-1]
        if not hasattr(last_output, 'requirements') or not last_output.requirements:
            logger.error("Validation Layer: ë§ˆì§€ë§‰ ë…¸ë“œì˜ ì¶œë ¥ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return "ê²€ì¦ ê²°ê³¼ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        logger.info(f"Validation Layer ê²°ê³¼ ê²°í•© ì™„ë£Œ: {len(last_output.requirements)}ì")
        return last_output.requirements
    
    def extract_requirements_analysis(self, final_output: str, original_input: str) -> Tuple[List[str], List[str]]:
        """
        Validation Layer ì „ìš©: ê²€ì¦ ê²°ê³¼ì—ì„œ í•„í„°ë§ëœ ìš”êµ¬ì‚¬í•­ê³¼ ì œê±°ëœ ìš”êµ¬ì‚¬í•­ì„ ì¶”ì¶œ
        (Ensemble LayerëŠ” ìš”êµ¬ì‚¬í•­ì„ ì œê±°í•˜ì§€ ì•Šê³  ê²€ì¦ ìƒíƒœë§Œ ë³€ê²½í•¨)
        """
        filtered_requirements = []
        removed_requirements = []
        
        try:
            logger.info(f"ìš”êµ¬ì‚¬í•­ ë¶„ì„ ì‹œì‘ - final_output ê¸¸ì´: {len(final_output)}")
            
            # í•„í„°ë§ëœ ìš”êµ¬ì‚¬í•­ í‘œ ì¶”ì¶œ
            filtered_table_match = re.search(r'\*\*í•„í„°ë§ëœ ìš”êµ¬ì‚¬í•­ í‘œ:\*\*(.*?)(?=\*\*ì œê±°ëœ ìš”êµ¬ì‚¬í•­:|\Z)', final_output, re.DOTALL)
            if filtered_table_match:
                filtered_table = filtered_table_match.group(1).strip()
                logger.info(f"í•„í„°ë§ëœ ìš”êµ¬ì‚¬í•­ í‘œ ì°¾ìŒ: {len(filtered_table)}ì")
                
                table_rows = re.findall(r'\|\s*([^|]+)\s*\|\s*([^|]+)\s*\|\s*([^|]+)\s*\|\s*([^|]+)\s*\|', filtered_table)
                logger.info(f"í…Œì´ë¸” í–‰ ì¶”ì¶œ: {len(table_rows)}ê°œ")
                
                for i, row in enumerate(table_rows):
                    try:
                        if len(row) >= 4 and row[0].strip() and not row[0].strip().startswith('ID') and not row[0].strip().startswith('-'):
                            req_id = row[0].strip()
                            req_text = row[1].strip()
                            source = row[2].strip() if len(row) > 2 else ""
                            status = row[3].strip() if len(row) > 3 else ""
                            if req_id and req_text:
                                filtered_requirements.append(f"{req_id}: {req_text} (ì¶œì²˜: {source}, ìƒíƒœ: {status})")
                                logger.debug(f"í•„í„°ë§ëœ ìš”êµ¬ì‚¬í•­ {i+1} ì¶”ê°€: {req_id}")
                    except (IndexError, AttributeError) as row_e:
                        logger.warning(f"í…Œì´ë¸” í–‰ {i+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {row_e}")
                        continue
            else:
                logger.warning("í•„í„°ë§ëœ ìš”êµ¬ì‚¬í•­ í‘œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            
            # ì œê±°ëœ ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ
            removed_match = re.search(r'\*\*ì œê±°ëœ ìš”êµ¬ì‚¬í•­:\*\*(.*?)$', final_output, re.DOTALL)
            if removed_match:
                removed_section = removed_match.group(1).strip()
                logger.info(f"ì œê±°ëœ ìš”êµ¬ì‚¬í•­ ì„¹ì…˜ ì°¾ìŒ: {len(removed_section)}ì")
                
                removed_lines = [line.strip() for line in removed_section.split('\n') if line.strip() and not line.strip().startswith('(')]
                for line in removed_lines:
                    if line and '-' in line:
                        removed_requirements.append(line)
                        logger.debug(f"ì œê±°ëœ ìš”êµ¬ì‚¬í•­ ì¶”ê°€: {line[:50]}...")
            else:
                logger.warning("ì œê±°ëœ ìš”êµ¬ì‚¬í•­ ì„¹ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            
            # í†µê³„ ë¡œê¹…
            try:
                original_table_rows = re.findall(r'\|\s*([^|]+)\s*\|\s*([^|]+)\s*\|', original_input)
                original_count = len([row for row in original_table_rows if len(row) >= 2 and row[0].strip() and not row[0].strip().startswith('ID') and not row[0].strip().startswith('-')])
                filtered_count = len(filtered_requirements)
                
                logger.info(f"Validation í•„í„°ë§ ê²°ê³¼: ì›ë³¸ {original_count}ê°œ â†’ í•„í„°ë§ í›„ {filtered_count}ê°œ (ì œê±°: {original_count - filtered_count}ê°œ)")
            except Exception as stat_e:
                logger.error(f"í†µê³„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {stat_e}")
            
        except Exception as e:
            logger.error(f"ìš”êµ¬ì‚¬í•­ ë¶„ì„ ì¤‘ ì „ì²´ ì˜¤ë¥˜ ë°œìƒ: {e}")
            logger.error(f"final_output ë‚´ìš© (ì²˜ìŒ 500ì): {final_output[:500] if final_output else 'None'}")
            # ë¹ˆ ê²°ê³¼ ë°˜í™˜í•˜ì—¬ 500 ì—ëŸ¬ ë°©ì§€
            return [], []
        
        return filtered_requirements, removed_requirements


class LayerExecutorFactory:
    """Layerë³„ ì‹¤í–‰ê¸°ë¥¼ ìƒì„±í•˜ëŠ” íŒ©í† ë¦¬ í´ë˜ìŠ¤"""
    
    @staticmethod
    def get_executor(layer_type: str):
        """Layer íƒ€ì…ì— ë”°ë¥¸ ì‹¤í–‰ê¸° ë°˜í™˜"""
        if layer_type == "generation":
            return GenerationLayerExecutor()
        elif layer_type == "ensemble":
            return EnsembleLayerExecutor()
        elif layer_type == "validation":
            return ValidationLayerExecutor()
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” Layer íƒ€ì…: {layer_type}")