"""
Layerë³„ ì‹¤í–‰ ë¡œì§ì„ ë‹´ë‹¹í•˜ëŠ” ëª¨ë“ˆ - LangChain ê¸°ë°˜ ë¦¬íŒ©í† ë§
"""
import logging
from typing import List, Tuple, Dict, Any

# Chain ê¸°ë°˜ ì‹¤í–‰ê¸° import
from .chain_executors import ChainBasedLayerExecutors

# LangChain imports
from src.langchain_parsers.output_parsers import (
    LayerOutputParser, 
    LayerOutput, 
    NodeOutput as LangChainNodeOutput,
    get_layer_prompt_template
)
from langchain_core.exceptions import OutputParserException

logger = logging.getLogger(__name__)

# Chain ê¸°ë°˜ ì‹¤í–‰ê¸° ì¸ìŠ¤í„´ìŠ¤
chain_executors = ChainBasedLayerExecutors()

# LangChain ê¸°ë°˜ ì‹¤í–‰ìœ¼ë¡œ ì™„ì „ ì „í™˜ (ë ˆê±°ì‹œ ì½”ë“œ ì œê±°)

def parse_structured_output_langchain(raw_output: str, layer_type: str = "requirement") -> Tuple[str, str]:
    """
    LangChain PydanticOutputParserë¥¼ ì‚¬ìš©í•œ êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì‹±
    ë ˆê±°ì‹œ í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•´ (general_output_str, forward_data_str) ë°˜í™˜
    """
    try:
        # Layer íƒ€ì…ì— ë”°ë¥¸ ì ì ˆí•œ íŒŒì„œ ì„ íƒ
        if layer_type == "requirement":
            parser = LayerOutputParser.get_requirements_parser()
        elif layer_type == "ensemble":
            parser = LayerOutputParser.get_ensemble_parser()
        elif layer_type == "validation":
            parser = LayerOutputParser.get_validation_parser()
        else:
            parser = LayerOutputParser.get_requirements_parser()  # ê¸°ë³¸ê°’
        
        # LangChain íŒŒì„œë¡œ êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì‹± ì‹œë„
        try:
            parsed_output: LayerOutput = parser.parse(raw_output)
            
            # LayerOutputì„ ë¬¸ìì—´ë¡œ ë³€í™˜ (ë ˆê±°ì‹œ í˜¸í™˜ì„±)
            general_output_str = parsed_output.content
            
            # forward_data ìƒì„± (êµ¬ì¡°í™”ëœ ë°ì´í„°ì—ì„œ ì¶”ì¶œ)
            forward_data_parts = []
            
            if parsed_output.requirements:
                forward_data_parts.append(f"Requirements: {', '.join(parsed_output.requirements)}")
            
            if parsed_output.final_decision:
                forward_data_parts.append(f"Decision: {parsed_output.final_decision}")
            
            if parsed_output.overall_valid is not None:
                forward_data_parts.append(f"Validation: {'PASS' if parsed_output.overall_valid else 'FAIL'}")
            
            forward_data_str = " | ".join(forward_data_parts) if forward_data_parts else parsed_output.content
            
            logger.info(f"LangChain êµ¬ì¡°í™”ëœ íŒŒì‹± ì„±ê³µ - Layer: {layer_type}")
            return general_output_str, forward_data_str
            
        except OutputParserException as parse_error:
            logger.warning(f"LangChain íŒŒì‹± ì‹¤íŒ¨, ë ˆê±°ì‹œ ë°©ì‹ìœ¼ë¡œ fallback: {str(parse_error)}")
            return fallback_parse_structured_output(raw_output)
            
    except Exception as e:
        logger.error(f"LangChain íŒŒì„œ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        return fallback_parse_structured_output(raw_output)


def fallback_parse_structured_output(text: str) -> Tuple[str, str]:
    """
    ë ˆê±°ì‹œ êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì‹± (LangChain íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì‚¬ìš©)
    """
    logger.info("ë ˆê±°ì‹œ êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì‹± ì‚¬ìš©")
    
    if not text or not text.strip():
        return "íŒŒì‹±í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.", ""
    
    text = text.strip()
    
    # forward_data íŒ¨í„´ë“¤ ì‹œë„
    forward_patterns = [
        r'\*\*Forward Data:\*\*\s*(.*?)(?=\n\n|\Z)',
        r'\*\*ë‹¤ìŒ ë ˆì´ì–´ ì…ë ¥:\*\*\s*(.*?)(?=\n\n|\Z)',
        r'\*\*Next Layer Input:\*\*\s*(.*?)(?=\n\n|\Z)',
        r'Forward Data:\s*(.*?)(?=\n\n|\Z)',
    ]
    
    forward_data = ""
    for pattern in forward_patterns:
        match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)
        if match:
            forward_data = match.group(1).strip()
            break
    
    # forward_dataê°€ ì—†ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ìš”ì•½ ì¶”ì¶œ
    if not forward_data:
        lines = text.split('\n')
        content_lines = [line.strip() for line in lines if line.strip() and not line.strip().startswith('#')]
        if content_lines:
            forward_data = content_lines[0][:200]  # ì²« ë²ˆì§¸ ì˜ë¯¸ìˆëŠ” ì¤„ì˜ ì²˜ìŒ 200ì
    
    # general_outputì€ ì „ì²´ í…ìŠ¤íŠ¸
    general_output = text
    
    return general_output, forward_data
def execute_generation_layer(nodes: List[Dict[str, Any]], layer_input: str, context_chunks: List[str]) -> Dict[str, Any]:
    """
    Generation Layer ì‹¤í–‰ - LangChain Chain ê¸°ë°˜
    Returns: {
        "node1": node1ì˜ general_output,
        "node2": node2ì˜ general_output,
        ...
        "forward_data": ëª¨ë“  ë…¸ë“œì˜ forward_dataë¥¼ appendí•œ ê²°ê³¼
    }
    """
    logger.info(f"LangChain Generation Layer ì‹¤í–‰ ì‹œì‘: {len(nodes)}ê°œ ë…¸ë“œ")
    
    try:
        # knowledge_base ì¶”ì¶œ (context_chunksì—ì„œ ìœ ì¶” ë˜ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©)
        knowledge_base = "nvme-2_2"  # ê¸°ë³¸ê°’, ì‹¤ì œë¡œëŠ” APIì—ì„œ ì „ë‹¬ë°›ì•„ì•¼ í•¨
        return chain_executors.execute_generation_layer_with_chains(nodes, layer_input, knowledge_base)
    except Exception as e:
        logger.error(f"Chain ê¸°ë°˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        # ìµœì†Œí•œì˜ ì˜¤ë¥˜ ì‘ë‹µ ë°˜í™˜
        return {
            "node1": f"ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}",
            "forward_data": ""
        }


def execute_ensemble_layer(nodes: List[Dict[str, Any]], layer_input: str, context_chunks: List[str]) -> Dict[str, Any]:
    """
    Ensemble Layer ì‹¤í–‰ - LangChain Chain ê¸°ë°˜
    Returns: {
        "node1": node1ì˜ general_output,
        "node2": node2ì˜ general_output,
        ...
        "forward_data": ëª¨ë“  ë…¸ë“œì˜ forward_dataë¥¼ appendí•œ ê²°ê³¼
    }
    """
    logger.info(f"LangChain Ensemble Layer ì‹¤í–‰ ì‹œì‘: {len(nodes)}ê°œ ë…¸ë“œ")
    
    try:
        knowledge_base = "nvme-2_2"  # ê¸°ë³¸ê°’
        return chain_executors.execute_ensemble_layer_with_chains(nodes, layer_input, knowledge_base)
    except Exception as e:
        logger.error(f"Chain ê¸°ë°˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        # ìµœì†Œí•œì˜ ì˜¤ë¥˜ ì‘ë‹µ ë°˜í™˜
        return {
            "node1": f"ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}",
            "forward_data": ""
        }


def execute_validation_layer(nodes: List[Dict[str, Any]], layer_input: str, context_chunks: List[str]) -> Dict[str, Any]:
    """
    Validation Layer ì‹¤í–‰ - LangChain Chain ê¸°ë°˜
    Returns: {
        "node1": node1ì˜ general_output,
        "node2": node2ì˜ general_output,
        ...
        "forward_data": ë§ˆì§€ë§‰ ë…¸ë“œì˜ forward_data (ë®ì–´ì“°ê¸° ë°©ì‹)
    }
    """
    logger.info(f"LangChain Validation Layer ì‹¤í–‰ ì‹œì‘: {len(nodes)}ê°œ ë…¸ë“œ")
    
    try:
        knowledge_base = "nvme-2_2"  # ê¸°ë³¸ê°’
        return chain_executors.execute_validation_layer_with_chains(nodes, layer_input, knowledge_base)
    except Exception as e:
        logger.error(f"Chain ê¸°ë°˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        # ìµœì†Œí•œì˜ ì˜¤ë¥˜ ì‘ë‹µ ë°˜í™˜
        return {
            "node1": f"ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}",
            "forward_data": ""
        }
    print(f"ğŸ¯ Final result forward_data length: {len(final_forward_data)}")
    print(f"ğŸ¯ Final result keys: {list(result.keys())}")
    
    logger.info(f"Validation Layer ì™„ë£Œ: ìµœì¢… forward_data ê¸¸ì´ {len(final_forward_data)}")
    return result


