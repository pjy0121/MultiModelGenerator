from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
import logging
import uuid
import os
import shutil
import asyncio
from typing import Dict

# Node-based workflow imports
from ..core.node_execution_engine import NodeExecutionEngine
from ..core.workflow_validator import WorkflowValidator
from ..core.config import LLM_CONFIG
from ..core.utils import format_sse_data
from ..core.models import (
    WorkflowExecutionRequest, 
    WorkflowDefinition,
    KnowledgeBase,
    KnowledgeBaseListResponse,
    SearchIntensity,
    LLMProvider
)
from ..services.vector_store_service import VectorStoreService
from ..services.llm_factory import LLMFactory

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="Node-based Workflow API",
    description="Multi-model AI system for requirements extraction using node-based workflows",
    version="2.0.0"
)

# íŒŒì¼ ì‹œìŠ¤í…œ ì‘ì—…ì„ ìœ„í•œ ê¸€ë¡œë²Œ ë½ (ë™ì‹œì„± ë¬¸ì œ í•´ê²°)
fs_lock = asyncio.Lock()

# VectorStoreService ì¸ìŠ¤í„´ìŠ¤ ì¶”ì  (KB ì‚­ì œ/ì´ë¦„ ë³€ê²½ ì‹œ ì—°ê²° ë‹«ê¸°ìš©)
_active_vector_services: Dict[int, VectorStoreService] = {}

def register_vector_service(service: VectorStoreService):
    """VectorStoreService ì¸ìŠ¤í„´ìŠ¤ ë“±ë¡"""
    service_id = id(service)
    _active_vector_services[service_id] = service
    return service_id

def close_kb_in_all_services(kb_name: str):
    """ëª¨ë“  í™œì„± VectorStoreServiceì—ì„œ íŠ¹ì • KBì˜ ì—°ê²° ë‹«ê¸°"""
    import gc
    for service_id, service in list(_active_vector_services.items()):
        try:
            service.close_and_remove_kb(kb_name)
        except Exception as e:
            logger.warning(f"KB '{kb_name}' ë‹«ê¸° ì‹¤íŒ¨ (service {service_id}): {e}")
    # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰
    gc.collect()
    logger.info(f"âœ… ëª¨ë“  ì„œë¹„ìŠ¤ì—ì„œ KB '{kb_name}' ì—°ê²° ë‹«í˜")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Global instances (stateless services only)
validator = WorkflowValidator()
# vector_store_serviceëŠ” ìš”ì²­ë³„ë¡œ ìƒì„±

# Active workflow executions tracking (multi-user support)
active_executions: Dict[str, NodeExecutionEngine] = {}

@app.get("/")
async def health():
    return {"status": "Node-based workflow API is running", "version": "2.0.0"}

@app.post("/validate-workflow")
async def validate_workflow(workflow: WorkflowDefinition):
    """ì›Œí¬í”Œë¡œìš° ìœ íš¨ì„± ê²€ì¦ (project_reference.md ì—°ê²° ì¡°ê±´ ê¸°ì¤€)"""
    try:
        result = validator.validate_workflow(workflow)
        return result
    except Exception as e:
        logger.error(f"Validation failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/execute-workflow-stream")
async def execute_workflow_stream(request: WorkflowExecutionRequest):
    """
    Node-based ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (ìŠ¤íŠ¸ë¦¬ë°)
    LLM ì‘ë‹µì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°í•˜ë©´ì„œ ìµœì¢… íŒŒì‹±ëœ ê²°ê³¼ë„ ë°˜í™˜
    """
    # Generate unique execution ID for this workflow
    execution_id = str(uuid.uuid4())
    
    async def generate_stream():
        execution_engine = None
        try:
            logger.info(f"Starting streaming workflow execution {execution_id} with {len(request.workflow.nodes)} nodes")
            
            # ì‹¤í–‰ ì—”ì§„ ìƒì„± ë° ë“±ë¡
            execution_engine = NodeExecutionEngine()
            active_executions[execution_id] = execution_engine
            logger.info(f"Registered execution {execution_id} for stop control")
            
            # ì²« ì´ë²¤íŠ¸ë¡œ execution_id ì „ë‹¬
            yield format_sse_data({
                'type': 'execution_started',
                'execution_id': execution_id,
                'message': 'Workflow execution started'
            })
            
            # ì‹¤í–‰ ì „ ê²€ì¦
            validation_result = validator.validate_workflow(request.workflow)
            if not validation_result["valid"]:
                error_details = {
                    'type': 'validation_error',
                    'message': 'Workflow validation failed',
                    'errors': validation_result['errors'],
                    'warnings': validation_result.get('warnings', [])
                }
                yield format_sse_data(error_details)
                return
            
            # ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (ë…ë¦½ì ì¸ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©)
            async for chunk in execution_engine.execute_workflow_stream(
                workflow=request.workflow
            ):
                yield format_sse_data(chunk)
                
                # ì™„ë£Œ ë˜ëŠ” ì—ëŸ¬ ì‹œ ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ
                if chunk.get('type') in ['complete', 'error']:
                    logger.info(f"Stream terminated with event: {chunk.get('type')}")
                    break
                
        except Exception as e:
            logger.error(f"Streaming workflow execution {execution_id} failed: {e}")
            yield format_sse_data({'type': 'error', 'message': str(e)})
        finally:
            # ì‹¤í–‰ ì™„ë£Œ ì‹œ ì •ë¦¬
            if execution_id in active_executions:
                del active_executions[execution_id]
                logger.info(f"Cleaned up execution {execution_id}")
    
    return StreamingResponse(
        generate_stream(),
        media_type="text/plain",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Content-Type": "text/event-stream"
        }
    )

@app.post("/stop-workflow/{execution_id}")
async def stop_workflow(execution_id: str):
    """
    ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ë‹¨
    
    íŠ¹ì • execution_idì˜ ì›Œí¬í”Œë¡œìš°ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.
    í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ë…¸ë“œëŠ” ì™„ë£Œí•˜ê³ , ìƒˆë¡œìš´ ë…¸ë“œ ì‹¤í–‰ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.
    ì´ë¯¸ ì™„ë£Œë˜ì—ˆê±°ë‚˜ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì›Œí¬í”Œë¡œìš°ì— ëŒ€í•œ ì¤‘ë‹¨ ìš”ì²­ë„ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.
    """
    try:
        if execution_id not in active_executions:
            logger.info(f"Execution {execution_id} not found or already completed")
            return {
                "success": True,
                "message": "ì›Œí¬í”Œë¡œìš°ê°€ ì´ë¯¸ ì™„ë£Œë˜ì—ˆê±°ë‚˜ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤."
            }
        
        # ì¤‘ë‹¨ í”Œë˜ê·¸ ì„¤ì •
        active_executions[execution_id].stop()
        logger.info(f"Stop signal sent to execution {execution_id}")
        
        return {
            "success": True,
            "message": "ì¤‘ë‹¨ ìš”ì²­ì´ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤. ì‹¤í–‰ ì¤‘ì¸ ë…¸ë“œëŠ” ì™„ë£Œ í›„ ì¤‘ë‹¨ë©ë‹ˆë‹¤."
        }
    except Exception as e:
        logger.error(f"Failed to stop workflow {execution_id}: {e}")
        # ì˜ˆì™¸ ë°œìƒ ì‹œì—ë„ ì¤‘ë‹¨ì€ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬
        return {
            "success": True,
            "message": "ì›Œí¬í”Œë¡œìš° ì¤‘ë‹¨ì´ ìš”ì²­ë˜ì—ˆìŠµë‹ˆë‹¤."
        }

@app.get("/knowledge-bases", response_model=KnowledgeBaseListResponse)
async def list_knowledge_bases():
    """ì§€ì‹ë² ì´ìŠ¤ ëª©ë¡ ì¡°íšŒ"""
    try:
        # ìš”ì²­ë³„ ë…ë¦½ì ì¸ VectorStoreService ìƒì„± ë° ë“±ë¡
        vector_store_service = VectorStoreService()
        register_vector_service(vector_store_service)
        knowledge_bases = []
        kb_names = await vector_store_service.get_knowledge_bases()
        
        # ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì§€ì‹ë² ì´ìŠ¤ ì •ë³´ ì¡°íšŒ (ì„±ëŠ¥ í–¥ìƒ ë° ë¸”ë¡œí‚¹ ë°©ì§€)
        import asyncio
        from concurrent.futures import ThreadPoolExecutor
        
        async def get_kb_info_safe(name: str):
            try:
                # ê° KBì— ëŒ€í•´ ë…ë¦½ì ì¸ VectorStoreService ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©
                kb_vector_service = VectorStoreService()
                register_vector_service(kb_vector_service)
                kb_info = await kb_vector_service.get_knowledge_base_info(name)
                return KnowledgeBase(
                    name=kb_info['name'],
                    chunk_count=kb_info.get('count', 0),  # VectorStoreëŠ” 'count' ì‚¬ìš©
                    created_at=kb_info.get('created_at', 'Unknown')  # ìƒì„±ì¼ ì •ë³´ê°€ ì—†ìœ¼ë©´ Unknown
                )
            except Exception as e:
                logger.warning(f"Failed to get info for KB {name}: {e}")
                # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì¶”ê°€
                return KnowledgeBase(
                    name=name,
                    chunk_count=0,  # ê¸°ë³¸ê°’
                    created_at="Unknown"
                )
        
        # ëª¨ë“  KB ì •ë³´ë¥¼ ë³‘ë ¬ë¡œ ì¡°íšŒ
        knowledge_bases = await asyncio.gather(*[get_kb_info_safe(name) for name in kb_names])
        
        return KnowledgeBaseListResponse(knowledge_bases=knowledge_bases)
        
    except Exception as e:
        logger.error(f"Failed to list knowledge bases: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/knowledge-bases/structure")
async def get_knowledge_base_structure():
    """ì§€ì‹ ë² ì´ìŠ¤ ë””ë ‰í† ë¦¬ êµ¬ì¡° ë°˜í™˜ (í´ë” í¬í•¨)"""
    try:
        kb_base_path = os.path.join(os.path.dirname(__file__), '..', '..', 'knowledge_bases')
        kb_base_path = os.path.abspath(kb_base_path)
        
        if not os.path.exists(kb_base_path):
            return {"structure": {}}
        
        structure = {}
        
        def scan_directory_structure(current_path: str, relative_path: str = "", parent_id: str = "root"):
            """ì¬ê·€ì ìœ¼ë¡œ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìŠ¤ìº”"""
            try:
                for item in os.listdir(current_path):
                    item_path = os.path.join(current_path, item)
                    
                    if os.path.isdir(item_path):
                        # .folder_marker íŒŒì¼ë¡œ í´ë” íŒë³„
                        folder_marker = os.path.join(item_path, '.folder_marker')
                        chroma_file = os.path.join(item_path, 'chroma.sqlite3')
                        
                        is_folder = os.path.exists(folder_marker)
                        
                        # KB íŒë³„: .folder_markerê°€ ì—†ê³ , chroma.sqlite3ê°€ ìˆìœ¼ë©´ KB
                        # í´ë”ë¡œ íŒì •ë˜ë©´ KBê°€ ë  ìˆ˜ ì—†ìŒ
                        is_kb = False
                        chunk_count = 0
                        
                        if not is_folder:
                            if os.path.exists(chroma_file):
                                try:
                                    file_size = os.path.getsize(chroma_file)
                                    # chroma.sqlite3ê°€ ì¡´ì¬í•˜ê³  í¬ê¸°ê°€ 0ë³´ë‹¤ í¬ë©´ KB
                                    if file_size > 0:
                                        is_kb = True
                                        # KBì˜ chunk ê°œìˆ˜ ê°€ì ¸ì˜¤ê¸°
                                        try:
                                            from ..services.vector_store import VectorStore
                                            new_relative = f"{relative_path}/{item}" if relative_path else item
                                            vector_store = VectorStore(new_relative)
                                            collection = vector_store.get_collection()
                                            chunk_count = collection.count()
                                            logger.info(f"KB '{new_relative}' has {chunk_count} chunks")
                                        except Exception as e:
                                            logger.warning(f"Failed to get chunk count for {item}: {e}")
                                            chunk_count = 0
                                except OSError as e:
                                    logger.warning(f"Failed to check chroma file size for {item}: {e}")
                                    pass
                        
                        # ìƒëŒ€ ê²½ë¡œ ê³„ì‚° (ì¤‘ë³µ ë°©ì§€)
                        if not is_kb:  # KBê°€ ì•„ë‹Œ ê²½ìš°ë§Œ ì—¬ê¸°ì„œ ê³„ì‚°
                            new_relative = f"{relative_path}/{item}" if relative_path else item
                        
                        item_id = f"{'kb' if is_kb else 'folder'}_{new_relative.replace('/', '_')}"
                        
                        if is_kb:
                            # KBë¡œ ê°„ì£¼
                            structure[item_id] = {
                                "type": "kb",
                                "name": item,
                                "parent": parent_id,
                                "actualKbName": new_relative,
                                "chunkCount": chunk_count
                            }
                        else:
                            # í´ë”ë¡œ ê°„ì£¼ (ë¹ˆ í´ë”ì¼ ìˆ˜ ìˆìŒ)
                            structure[item_id] = {
                                "type": "folder",
                                "name": item,
                                "parent": parent_id
                            }
                            # í•˜ìœ„ ë””ë ‰í† ë¦¬ ìŠ¤ìº”
                            scan_directory_structure(item_path, new_relative, item_id)
            except Exception as e:
                logger.error(f"ë””ë ‰í† ë¦¬ ìŠ¤ìº” ì‹¤íŒ¨ ({current_path}): {e}")
        
        scan_directory_structure(kb_base_path)
        return {"structure": structure}
        
    except Exception as e:
        logger.error(f"Failed to get knowledge base structure: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/knowledge-bases/create-folder")
async def create_folder(request: dict):
    """í´ë” ìƒì„± (ë™ì‹œì„± ì•ˆì „)"""
    async with fs_lock:  # ë½ íšë“
        try:
            folder_path = request.get("folder_path", "")
            
            if not folder_path:
                raise HTTPException(status_code=400, detail="folder_path is required")
            
            kb_base_path = os.path.join(os.path.dirname(__file__), '..', '..', 'knowledge_bases')
            kb_base_path = os.path.abspath(kb_base_path)
            
            # ì „ì²´ ê²½ë¡œ ìƒì„±
            full_path = os.path.join(kb_base_path, folder_path)
            
            # ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ (ë½ ë‚´ë¶€ì—ì„œ ì¬í™•ì¸)
            if os.path.exists(full_path):
                raise HTTPException(status_code=409, detail=f"Folder '{folder_path}' already exists")
            
            # í´ë” ìƒì„±
            os.makedirs(full_path, exist_ok=False)
            
            # .folder_marker íŒŒì¼ ìƒì„± (ChromaDBì™€ êµ¬ë¶„í•˜ê¸° ìœ„í•´)
            marker_file = os.path.join(full_path, '.folder_marker')
            with open(marker_file, 'w') as f:
                f.write('This is a user-created folder, not a knowledge base.')
            
            logger.info(f"Folder created with marker: '{folder_path}'")
            
            return {
                "success": True,
                "message": f"Folder '{folder_path}' created successfully",
                "folder_path": folder_path
            }
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Failed to create folder: {e}")
            raise HTTPException(status_code=500, detail=str(e))

@app.delete("/knowledge-bases/delete-folder")
async def delete_folder(request: dict):
    """í´ë” ì‚­ì œ (ë‚´ë¶€ì˜ ëª¨ë“  KBë„ í•¨ê»˜ ì‚­ì œ, ë™ì‹œì„± ì•ˆì „)"""
    async with fs_lock:  # ë½ íšë“
        try:
            folder_path = request.get("folder_path", "")
            
            if not folder_path:
                raise HTTPException(status_code=400, detail="folder_path is required")
            
            kb_base_path = os.path.join(os.path.dirname(__file__), '..', '..', 'knowledge_bases')
            kb_base_path = os.path.abspath(kb_base_path)
            
            # ì „ì²´ ê²½ë¡œ ìƒì„±
            full_path = os.path.join(kb_base_path, folder_path)
            
            # ë½ ë‚´ë¶€ì—ì„œ ì¡´ì¬ ì—¬ë¶€ ì¬í™•ì¸
            if not os.path.exists(full_path):
                raise HTTPException(status_code=404, detail=f"Folder '{folder_path}' not found")
            
            if not os.path.isdir(full_path):
                raise HTTPException(status_code=400, detail=f"'{folder_path}' is not a folder")
            
            # í´ë” ì „ì²´ ì‚­ì œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
            import time
            import gc
            
            max_retries = 5
            for attempt in range(max_retries):
                try:
                    # ê°€ë¹„ì§€ ì»¤ë ‰ì…˜ ê°•ì œ ì‹¤í–‰ (ChromaDB íŒŒì¼ í•¸ë“¤ í•´ì œ)
                    gc.collect()
                    
                    # readonly ì†ì„± ì œê±° (ì¬ê·€ì )
                    def remove_readonly(func, path, excinfo):
                        os.chmod(path, 0o777)
                        func(path)
                    
                    shutil.rmtree(full_path, onerror=remove_readonly)
                    logger.info(f"Folder deleted: '{folder_path}'")
                    break
                except (PermissionError, OSError) as e:
                    if attempt < max_retries - 1:
                        logger.warning(f"Error deleting folder '{folder_path}', retrying... (attempt {attempt + 1}): {e}")
                        time.sleep(0.5 + attempt * 0.2)  # ì ì§„ì  ë°±ì˜¤í”„
                    else:
                        logger.error(f"Failed to delete folder '{folder_path}' after {max_retries} attempts: {e}")
                        raise HTTPException(
                            status_code=500,
                            detail=f"Cannot delete folder: files are in use. Please close any applications using them and try again. Error: {str(e)}"
                        )
            
            return {
                "success": True,
                "message": f"Folder '{folder_path}' deleted successfully",
                "folder_path": folder_path
            }
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Failed to delete folder: {e}")
            raise HTTPException(status_code=500, detail=str(e))

@app.post("/search-knowledge-base")
async def search_knowledge_base(request: dict):
    """ì§€ì‹ ë² ì´ìŠ¤ ê²€ìƒ‰"""
    try:
        query = request.get("query", "")
        knowledge_base = request.get("knowledge_base", "")
        top_k = request.get("top_k", 5)
        
        if not query or not knowledge_base:
            raise HTTPException(status_code=400, detail="Query and knowledge_base are required")
        
        # top_kë¥¼ search_intensityë¡œ ë§¤í•‘
        search_intensity = SearchIntensity.from_top_k(top_k)
        
        # ìš”ì²­ë³„ ë…ë¦½ì ì¸ VectorStoreService ìƒì„± ë° ë“±ë¡
        vector_store_service = VectorStoreService()
        register_vector_service(vector_store_service)
        results = await vector_store_service.search(
            kb_name=knowledge_base,
            query=query,
            search_intensity=search_intensity,
            rerank_info=None  # ê¸°ë³¸ì ìœ¼ë¡œ rerank ë¹„í™œì„±í™”
        )
        
        return {
            "results": results,
            "query": query,
            "knowledge_base": knowledge_base,
            "count": len(results)
        }
        
    except Exception as e:
        logger.error(f"Knowledge base search failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/knowledge-bases/delete")
async def delete_knowledge_base(request: dict):
    """ì§€ì‹ ë² ì´ìŠ¤ ì‚­ì œ (ë™ì‹œì„± ì•ˆì „)"""
    async with fs_lock:  # ë½ íšë“
        try:
            kb_name = request.get("kb_name", "")
            
            if not kb_name:
                raise HTTPException(status_code=400, detail="kb_name is required")
            
            from ..core.utils import get_kb_path
            import time
            import gc
            
            kb_path = get_kb_path(kb_name)
            
            logger.info(f"KB Delete request - kb_name: '{kb_name}'")
            logger.info(f"Resolved kb_path: '{kb_path}', exists: {os.path.exists(kb_path)}")
            
            # ë½ ë‚´ë¶€ì—ì„œ ì¡´ì¬ ì—¬ë¶€ ì¬í™•ì¸
            if not os.path.exists(kb_path):
                raise HTTPException(status_code=404, detail=f"Knowledge base '{kb_name}' not found at '{kb_path}'")
            
            # CRITICAL: ëª¨ë“  VectorStoreServiceì—ì„œ ì´ KBì˜ ChromaDB ì—°ê²° ë‹«ê¸°
            logger.info(f"ğŸ”’ KB '{kb_name}'ì˜ ëª¨ë“  ChromaDB ì—°ê²° ë‹«ëŠ” ì¤‘...")
            close_kb_in_all_services(kb_name)
            await asyncio.sleep(0.3)  # íŒŒì¼ í•¸ë“¤ì´ ì™„ì „íˆ ë‹«í ì‹œê°„ ì œê³µ
            
            # ChromaDB íŒŒì¼ ì ê¸ˆ í•´ì œë¥¼ ìœ„í•œ ê°•í™”ëœ ì¬ì‹œë„ ë¡œì§
            max_retries = 5
            for attempt in range(max_retries):
                try:
                    # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰ (ChromaDB íŒŒì¼ í•¸ë“¤ í•´ì œ)
                    gc.collect()
                    await asyncio.sleep(0.1)  # ë¹„ë™ê¸° ëŒ€ê¸°
                    
                    # readonly ì†ì„± ì œê±° í•¨ìˆ˜
                    def remove_readonly(func, path, excinfo):
                        try:
                            os.chmod(path, 0o777)
                            func(path)
                        except Exception as e:
                            logger.warning(f"Failed to remove readonly for {path}: {e}")
                    
                    # ë””ë ‰í† ë¦¬ ì „ì²´ ì‚­ì œ
                    shutil.rmtree(kb_path, onerror=remove_readonly)
                    logger.info(f"Knowledge base '{kb_name}' deleted successfully")
                    break
                except (PermissionError, OSError) as pe:
                    if attempt < max_retries - 1:
                        logger.warning(f"Error deleting '{kb_name}', retrying... (attempt {attempt + 1}/{max_retries}): {pe}")
                        await asyncio.sleep(0.5 + attempt * 0.2)  # ì ì§„ì  ë°±ì˜¤í”„
                    else:
                        logger.error(f"Failed to delete '{kb_name}' after {max_retries} attempts: {pe}")
                        raise HTTPException(
                            status_code=500, 
                            detail=f"Cannot delete knowledge base: files are in use. Please close any applications using them and try again. Error: {str(pe)}"
                        )
            
            return {
                "success": True,
                "message": f"Knowledge base '{kb_name}' deleted successfully"
            }
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Failed to delete knowledge base '{kb_name}': {e}")
            raise HTTPException(status_code=500, detail=str(e))

@app.put("/knowledge-bases/rename-folder")
async def rename_folder(request: dict):
    """í´ë” ì´ë¦„ ë³€ê²½ (ë™ì‹œì„± ì•ˆì „)"""
    async with fs_lock:
        try:
            old_path = request.get("old_path", "")
            new_name = request.get("new_name", "")
            
            if not old_path or not new_name:
                raise HTTPException(status_code=400, detail="old_path and new_name are required")
            
            kb_base_path = os.path.join(os.path.dirname(__file__), '..', '..', 'knowledge_bases')
            kb_base_path = os.path.abspath(kb_base_path)
            
            # ì „ì²´ ê²½ë¡œ ìƒì„±
            full_old_path = os.path.join(kb_base_path, old_path)
            
            # ì¡´ì¬ í™•ì¸
            if not os.path.exists(full_old_path):
                raise HTTPException(status_code=404, detail=f"Folder '{old_path}' not found")
            
            if not os.path.isdir(full_old_path):
                raise HTTPException(status_code=400, detail=f"'{old_path}' is not a folder")
            
            # ìƒˆ ê²½ë¡œ ê³„ì‚° (ê°™ì€ ë¶€ëª¨ ë””ë ‰í† ë¦¬ ë‚´ì—ì„œ)
            parent_dir = os.path.dirname(full_old_path)
            full_new_path = os.path.join(parent_dir, new_name)
            
            # ìƒˆ ì´ë¦„ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            if os.path.exists(full_new_path):
                raise HTTPException(status_code=409, detail=f"Folder or KB '{new_name}' already exists in the same location")
            
            # ì´ë¦„ ë³€ê²½
            os.rename(full_old_path, full_new_path)
            
            # ìƒˆ ìƒëŒ€ ê²½ë¡œ ê³„ì‚°
            new_relative_path = os.path.relpath(full_new_path, kb_base_path).replace('\\', '/')
            
            logger.info(f"Folder renamed: '{old_path}' -> '{new_relative_path}'")
            
            return {
                "success": True,
                "message": f"Folder renamed successfully",
                "old_path": old_path,
                "new_path": new_relative_path
            }
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Failed to rename folder: {e}")
            raise HTTPException(status_code=500, detail=str(e))

@app.post("/knowledge-bases/rename")
async def rename_knowledge_base(request: dict):
    """ì§€ì‹ ë² ì´ìŠ¤ ì´ë¦„ ë³€ê²½ (ê°™ì€ ë””ë ‰í† ë¦¬ ë‚´ì—ì„œë§Œ, ë™ì‹œì„± ì•ˆì „)"""
    async with fs_lock:
        try:
            old_name = request.get("old_name", "")
            new_name = request.get("new_name", "")
            
            if not old_name or not new_name:
                raise HTTPException(status_code=400, detail="old_name and new_name are required")
            
            if old_name == new_name:
                raise HTTPException(status_code=400, detail="New name must be different from old name")
            
            from ..core.utils import get_kb_path
            import gc
            
            old_path = get_kb_path(old_name)
            
            logger.info(f"KB Rename request - old_name: '{old_name}', new_name: '{new_name}'")
            logger.info(f"Resolved old_path: '{old_path}', exists: {os.path.exists(old_path)}")
            
            if not os.path.exists(old_path):
                raise HTTPException(status_code=404, detail=f"Knowledge base '{old_name}' not found at '{old_path}'")
            
            # ê°™ì€ ë¶€ëª¨ ë””ë ‰í† ë¦¬ ë‚´ì—ì„œ ì´ë¦„ë§Œ ë³€ê²½
            parent_dir = os.path.dirname(old_path)
            new_path = os.path.join(parent_dir, new_name)
            
            logger.info(f"Target new_path: '{new_path}'")
            
            if os.path.exists(new_path):
                raise HTTPException(status_code=409, detail=f"Knowledge base '{new_name}' already exists")
            
            # CRITICAL: ëª¨ë“  VectorStoreServiceì—ì„œ ì´ KBì˜ ChromaDB ì—°ê²° ë‹«ê¸°
            logger.info(f"ğŸ”’ KB '{old_name}'ì˜ ëª¨ë“  ChromaDB ì—°ê²° ë‹«ëŠ” ì¤‘...")
            close_kb_in_all_services(old_name)
            await asyncio.sleep(0.3)  # íŒŒì¼ í•¸ë“¤ì´ ì™„ì „íˆ ë‹«í ì‹œê°„ ì œê³µ
            
            # ChromaDB íŒŒì¼ ì ê¸ˆ í•´ì œë¥¼ ìœ„í•œ ì¬ì‹œë„ ë¡œì§
            max_retries = 5
            for attempt in range(max_retries):
                try:
                    # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰ (ChromaDB íŒŒì¼ í•¸ë“¤ í•´ì œ)
                    gc.collect()
                    await asyncio.sleep(0.1)  # ë¹„ë™ê¸° ëŒ€ê¸°
                    
                    # ë””ë ‰í† ë¦¬ ì´ë¦„ ë³€ê²½
                    os.rename(old_path, new_path)
                    logger.info(f"Knowledge base renamed successfully on attempt {attempt + 1}")
                    break
                except (PermissionError, OSError) as e:
                    if attempt < max_retries - 1:
                        logger.warning(f"Error renaming '{old_name}', retrying... (attempt {attempt + 1}/{max_retries}): {e}")
                        await asyncio.sleep(0.5 + attempt * 0.2)  # ì ì§„ì  ë°±ì˜¤í”„
                    else:
                        logger.error(f"Failed to rename '{old_name}' after {max_retries} attempts: {e}")
                        raise HTTPException(
                            status_code=500,
                            detail=f"Cannot rename knowledge base: files are in use. Please close any applications using them and try again. Error: {str(e)}"
                        )
            
            # ìƒˆ ìƒëŒ€ ê²½ë¡œ ê³„ì‚°
            kb_base_path = os.path.join(os.path.dirname(__file__), '..', '..', 'knowledge_bases')
            kb_base_path = os.path.abspath(kb_base_path)
            new_relative_path = os.path.relpath(new_path, kb_base_path).replace('\\', '/')
            
            logger.info(f"Knowledge base renamed: '{old_name}' -> '{new_relative_path}'")
            
            return {
                "success": True,
                "message": f"Knowledge base renamed successfully",
                "old_name": old_name,
                "new_name": new_relative_path
            }
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Failed to rename knowledge base '{old_name}': {e}")
            raise HTTPException(status_code=500, detail=str(e))

@app.put("/knowledge-bases/move-folder")
async def move_folder(request: dict):
    """í´ë”ë¥¼ ë‹¤ë¥¸ í´ë”ë¡œ ì´ë™ (ë™ì‹œì„± ì•ˆì „)"""
    async with fs_lock:
        try:
            old_path = request.get("old_path", "")
            target_folder = request.get("target_folder", "")
            
            if not old_path:
                raise HTTPException(status_code=400, detail="old_path is required")
            
            kb_base_path = os.path.join(os.path.dirname(__file__), '..', '..', 'knowledge_bases')
            kb_base_path = os.path.abspath(kb_base_path)
            
            # ì´ë™í•  í´ë”ì˜ ì „ì²´ ê²½ë¡œ
            full_old_path = os.path.join(kb_base_path, old_path)
            
            logger.info(f"Folder Move request - old_path: '{old_path}', target_folder: '{target_folder}'")
            logger.info(f"Resolved full_old_path: '{full_old_path}', exists: {os.path.exists(full_old_path)}")
            
            if not os.path.exists(full_old_path):
                raise HTTPException(status_code=404, detail=f"Folder '{old_path}' not found")
            
            if not os.path.isdir(full_old_path):
                raise HTTPException(status_code=400, detail=f"'{old_path}' is not a folder")
            
            # ëŒ€ìƒ í´ë” ê²½ë¡œ ê³„ì‚°
            if target_folder and target_folder != 'root':
                target_dir = os.path.join(kb_base_path, target_folder)
            else:
                target_dir = kb_base_path
            
            # ëŒ€ìƒ í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
            os.makedirs(target_dir, exist_ok=True)
            
            # í´ë” ì´ë¦„ ì¶”ì¶œ
            folder_basename = os.path.basename(full_old_path)
            new_path = os.path.join(target_dir, folder_basename)
            
            logger.info(f"Target new_path: '{new_path}'")
            
            # ê°™ì€ ìœ„ì¹˜ë¡œ ì´ë™í•˜ë ¤ëŠ”ì§€ í™•ì¸
            if os.path.normpath(full_old_path) == os.path.normpath(new_path):
                logger.info(f"Folder is already in target location")
                return {
                    "success": True,
                    "message": f"Folder is already in target location",
                    "old_path": old_path,
                    "new_path": os.path.relpath(new_path, kb_base_path).replace('\\', '/')
                }
            
            # ìƒˆ ê²½ë¡œê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            if os.path.exists(new_path):
                raise HTTPException(status_code=409, detail=f"Folder '{folder_basename}' already exists in target location")
            
            # ìê¸° ìì‹ ì˜ í•˜ìœ„ í´ë”ë¡œ ì´ë™í•˜ë ¤ëŠ”ì§€ í™•ì¸
            if new_path.startswith(full_old_path + os.sep):
                raise HTTPException(status_code=400, detail="Cannot move folder into its own subfolder")
            
            # ì´ë™
            shutil.move(full_old_path, new_path)
            
            # ìƒˆ ìƒëŒ€ ê²½ë¡œ ê³„ì‚°
            new_relative_path = os.path.relpath(new_path, kb_base_path).replace('\\', '/')
            
            logger.info(f"Folder moved: '{old_path}' -> '{new_relative_path}'")
            
            return {
                "success": True,
                "message": f"Folder moved successfully",
                "old_path": old_path,
                "new_path": new_relative_path
            }
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Failed to move folder: {e}")
            raise HTTPException(status_code=500, detail=str(e))

@app.post("/knowledge-bases/move")
async def move_knowledge_base(request: dict):
    """ì§€ì‹ ë² ì´ìŠ¤ë¥¼ ë‹¤ë¥¸ í´ë”ë¡œ ì´ë™ (ë™ì‹œì„± ì•ˆì „)"""
    async with fs_lock:
        try:
            kb_name = request.get("kb_name", "")
            target_folder = request.get("target_folder", "")
            
            if not kb_name:
                raise HTTPException(status_code=400, detail="kb_name is required")
            
            from ..core.utils import get_kb_path
            
            old_path = get_kb_path(kb_name)
            
            logger.info(f"KB Move request - kb_name: '{kb_name}', target_folder: '{target_folder}'")
            logger.info(f"Resolved old_path: '{old_path}'")
            logger.info(f"Path exists: {os.path.exists(old_path)}")
            
            if not os.path.exists(old_path):
                raise HTTPException(status_code=404, detail=f"Knowledge base '{kb_name}' not found at '{old_path}'")
            
            # ëŒ€ìƒ í´ë” ê²½ë¡œ ìƒì„±
            kb_base_path = os.path.join(os.path.dirname(__file__), '..', '..', 'knowledge_bases')
            kb_base_path = os.path.abspath(kb_base_path)
            
            if target_folder and target_folder != 'root':
                target_dir = os.path.join(kb_base_path, target_folder)
            else:
                target_dir = kb_base_path
            
            # ëŒ€ìƒ í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
            os.makedirs(target_dir, exist_ok=True)
            
            # KB ì´ë¦„ ì¶”ì¶œ
            kb_basename = os.path.basename(old_path)
            new_path = os.path.join(target_dir, kb_basename)
            
            logger.info(f"Target new_path: '{new_path}'")
            
            # ê°™ì€ ìœ„ì¹˜ë¡œ ì´ë™í•˜ë ¤ëŠ”ì§€ í™•ì¸
            if os.path.normpath(old_path) == os.path.normpath(new_path):
                logger.info(f"KB is already in target location")
                return {
                    "success": True,
                    "message": f"Knowledge base is already in target location",
                    "old_path": kb_name,
                    "new_path": os.path.relpath(new_path, kb_base_path).replace('\\', '/')
                }
            
            if os.path.exists(new_path):
                raise HTTPException(status_code=409, detail=f"Knowledge base '{kb_basename}' already exists in target folder")
            
            # ì´ë™
            shutil.move(old_path, new_path)
            
            # ìƒˆ ìƒëŒ€ ê²½ë¡œ ê³„ì‚°
            new_relative_path = os.path.relpath(new_path, kb_base_path).replace('\\', '/')
            
            logger.info(f"Knowledge base moved: '{kb_name}' -> '{new_relative_path}'")
            
            return {
                "success": True,
                "message": f"Knowledge base moved successfully",
                "old_path": kb_name,
                "new_path": new_relative_path
            }
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Failed to move knowledge base '{kb_name}': {e}")
            raise HTTPException(status_code=500, detail=str(e))

# Helper functions for KB creation
def _process_plain_text(text_content: str) -> str:
    """Plain text ì²˜ë¦¬"""
    logger.info("Using plain text directly")
    return text_content

def _process_base64_text(text_content_base64: str) -> str:
    """Base64 ì¸ì½”ë”©ëœ í…ìŠ¤íŠ¸ ì²˜ë¦¬"""
    import base64
    logger.info("Processing base64 text content...")
    try:
        text_bytes = base64.b64decode(text_content_base64, validate=True)
        text = text_bytes.decode('utf-8')
        logger.info("Successfully decoded base64 text")
        return text
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Invalid base64 content: {str(e)}")

def _process_file_upload(file_content_base64: str, file_type: str, doc_processor) -> str:
    """íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬ (PDF ë˜ëŠ” TXT)"""
    import base64
    import tempfile
    
    logger.info(f"Processing {file_type.upper()} file...")
    
    try:
        file_content = base64.b64decode(file_content_base64)
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Invalid base64 file content: {str(e)}")
    
    if file_type == "pdf":
        # PDF íŒŒì¼ ì²˜ë¦¬
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as temp_file:
            temp_file.write(file_content)
            temp_pdf_path = temp_file.name
        
        try:
            text = doc_processor.extract_text_from_pdf(temp_pdf_path)
            logger.info(f"Extracted text from PDF: {len(text)} characters")
            return text
        finally:
            try:
                os.unlink(temp_pdf_path)
            except:
                pass
    
    elif file_type == "txt":
        # TXT íŒŒì¼ ì²˜ë¦¬ (ë‹¤ì¤‘ ì¸ì½”ë”© ì§€ì›)
        try:
            text = file_content.decode('utf-8')
            logger.info(f"Loaded text from TXT file (UTF-8): {len(text)} characters")
        except UnicodeDecodeError:
            try:
                text = file_content.decode('cp949')  # í•œê¸€ Windows
                logger.info(f"Loaded text from TXT file (CP949): {len(text)} characters")
            except:
                text = file_content.decode('latin-1')  # ìµœí›„ì˜ ìˆ˜ë‹¨
                logger.info(f"Loaded text from TXT file (Latin-1): {len(text)} characters")
        return text
    
    else:
        raise HTTPException(status_code=400, detail=f"Unsupported file type: {file_type}")

@app.post("/knowledge-bases/create")
async def create_knowledge_base(request: dict):
    """ì§€ì‹ ë² ì´ìŠ¤ ìƒì„± (plain text, base64 text, ë˜ëŠ” íŒŒì¼ ì—…ë¡œë“œ)"""
    async with fs_lock:
        try:
            # ìš”ì²­ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
            kb_name_input = request.get("kb_name", "")
            chunk_type = request.get("chunk_type", "sentence")
            text_content = request.get("text_content", "")
            file_content_base64 = request.get("file_content", "")
            chunk_size = request.get("chunk_size", 8000)
            chunk_overlap = request.get("chunk_overlap", 200)
            target_folder = request.get("target_folder", "")
            
            # ì…ë ¥ ê²€ì¦
            if not kb_name_input:
                raise HTTPException(status_code=400, detail="kb_name is required")
            
            if not text_content and not file_content_base64:
                raise HTTPException(status_code=400, detail="Either text_content or file_content is required")
            
            if chunk_type not in ["keyword", "sentence", "custom"]:
                raise HTTPException(status_code=400, detail="chunk_type must be one of: keyword, sentence, custom")
            
            # KB ì´ë¦„ ë° ê²½ë¡œ ì„¤ì •
            prefix_map = {"keyword": "keyword-", "sentence": "sentence-", "custom": "custom-"}
            kb_name = f"{prefix_map[chunk_type]}{kb_name_input}"
            
            kb_base_path = os.path.join(os.path.dirname(__file__), '..', '..', 'knowledge_bases')
            kb_base_path = os.path.abspath(kb_base_path)
            
            if target_folder and target_folder != 'root':
                kb_full_name = f"{target_folder}/{kb_name}"
                kb_dir = os.path.join(kb_base_path, target_folder)
            else:
                kb_full_name = kb_name
                kb_dir = kb_base_path
            
            os.makedirs(kb_dir, exist_ok=True)
            
            from ..core.utils import get_kb_path
            kb_path = get_kb_path(kb_full_name)
            
            logger.info(f"KB Create request - kb_name: '{kb_name}', chunk_type: '{chunk_type}', target_folder: '{target_folder}'")
            logger.info(f"Full KB name: '{kb_full_name}', path: '{kb_path}'")
            
            if os.path.exists(kb_path):
                raise HTTPException(status_code=409, detail=f"Knowledge base '{kb_name}' already exists in this location")
            
            # chunk_typeì— ë”°ë¼ chunk_size ìë™ ì„¤ì •
            if chunk_type == "keyword":
                chunk_size = 1000
                chunk_overlap = 100
            elif chunk_type == "sentence":
                chunk_size = 8000
                chunk_overlap = 200
            
            logger.info(f"Building KB with chunk_size={chunk_size}, chunk_overlap={chunk_overlap}")
            
            # DocumentProcessor ë° VectorStore ì´ˆê¸°í™”
            from ..services.document_processor import DocumentProcessor
            from ..services.vector_store import VectorStore
            
            doc_processor = DocumentProcessor(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
            vector_store = VectorStore(kb_full_name)
            
            # ì…ë ¥ ë°©ì‹ì— ë”°ë¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            if file_content_base64:
                # íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬
                file_type = request.get("file_type", "pdf")
                text = _process_file_upload(file_content_base64, file_type, doc_processor)
            
            elif text_content:
                # í…ìŠ¤íŠ¸ ì…ë ¥ ì²˜ë¦¬
                text_type = request.get("text_type", "plain")
                
                if text_type == "base64":
                    text = _process_base64_text(text_content)
                else:  # plain
                    text = _process_plain_text(text_content)
            
            # í…ìŠ¤íŠ¸ ê²€ì¦
            if not text.strip():
                raise HTTPException(status_code=400, detail="Text content is empty")
            
            logger.info(f"Text length: {len(text)} characters")
            
            # ì²­í‚¹ ë° ì„ë² ë”© ìƒì„±
            logger.info("Starting chunking...")
            chunks = doc_processor.semantic_chunking(text)
            logger.info(f"Created {len(chunks)} chunks")
            
            if not chunks:
                raise HTTPException(status_code=400, detail="Failed to create chunks from text")
            
            logger.info("Generating embeddings...")
            chunks_with_embeddings = doc_processor.generate_embeddings(chunks)
            logger.info("Embeddings generated")
            
            # ë²¡í„° DB ì €ì¥
            logger.info("Storing in vector database...")
            vector_store.store_chunks(chunks_with_embeddings)
            logger.info(f"Knowledge base '{kb_full_name}' created successfully with {len(chunks)} chunks")
            
            return {
                "success": True,
                "message": f"Knowledge base '{kb_name}' created successfully",
                "kb_name": kb_full_name,
                "chunk_type": chunk_type,
                "chunk_size": chunk_size,
                "chunk_overlap": chunk_overlap,
                "chunk_count": len(chunks)
            }
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Failed to create knowledge base: {e}")
            import traceback
            traceback.print_exc()
            raise HTTPException(status_code=500, detail=str(e))

@app.get("/available-models/{provider}")
async def get_available_models(provider: str):
    """Providerë³„ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
    try:
        # Normalize provider
        provider = provider.lower()
        if provider not in LLM_CONFIG["supported_providers"]:
            supported_providers = ", ".join(LLM_CONFIG["supported_providers"])
            raise HTTPException(status_code=400, detail=f"Unsupported provider. Only '{supported_providers}' are supported.")

        # ìš”ì²­ë³„ ë…ë¦½ì ì¸ LLMFactory ì¸ìŠ¤í„´ìŠ¤ë¡œ ì™„ì „ ë³‘ë ¬ ì²˜ë¦¬
        import asyncio
        from concurrent.futures import ThreadPoolExecutor
        
        def get_models_sync():
            """ë™ê¸°ì  ëª¨ë¸ ì¡°íšŒë¥¼ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰ - ë¸”ë¡œí‚¹ ë°©ì§€"""
            llm_factory = LLMFactory()  # ìš”ì²­ë³„ ë…ë¦½ ì¸ìŠ¤í„´ìŠ¤
            try:
                client = llm_factory.get_client(provider)
                if not client:
                    raise Exception(f"Failed to create client for {provider}")
                    
                if not client.is_available():
                    if provider == LLMProvider.INTERNAL:
                        raise Exception("Internal LLM service is not available. Please check INTERNAL_API_KEY and INTERNAL_API_ENDPOINT environment variables.")
                    else:
                        raise Exception(f"{provider} service is not available")
                        
                return client.get_available_models()
            except Exception as e:
                raise e
        
        # ThreadPoolExecutorë¡œ ì™„ì „ ë¹„ë™ê¸° ì‹¤í–‰í•˜ì—¬ ëª¨ë“  ìš”ì²­ ë¸”ë¡œí‚¹ ë°©ì§€
        loop = asyncio.get_event_loop()
        with ThreadPoolExecutor(max_workers=2) as executor:
            models = await loop.run_in_executor(executor, get_models_sync)
        
        return models
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get models for {provider}: {e}")
        raise HTTPException(status_code=500, detail=str(e))