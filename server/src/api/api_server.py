from fastapi import FastAPI, HTTPException, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import uvicorn
import time
from datetime import datetime
import logging
from typing import List
from ..core.workflow_engine import WorkflowEngine
from ..core.prompts import get_default_prompt

from ..core.config import Config
from ..services.vector_store import VectorStore
from ..services.perplexity_client import PerplexityClient
from ..core.models import (
    RequirementRequest, 
    RequirementResponse, 
    ErrorResponse, 
    KnowledgeBaseInfo, 
    KnowledgeBaseListResponse,
    WorkflowRequest, 
    WorkflowResponse,
    # ìƒˆë¡œìš´ ê°œë³„ ë…¸ë“œ ì‹¤í–‰ ëª¨ë¸ë“¤
    SearchRequest,
    SearchResponse,
    SingleNodeRequest,
    SingleNodeResponse,
    EnsembleRequest,
    ValidationRequest,
    ValidationResponse,
    ValidationChange,
    NodeConfig,
    NodeOutput,
    ModelType,
    # ìƒˆë¡œìš´ Layerë³„ ì‹¤í–‰ ëª¨ë¸ë“¤
    LayerExecutionRequest,
    LayerExecutionResponse,
    ValidationLayerResponse,
    # ìƒˆë¡œìš´ Layerë³„ í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ ëª¨ë¸ë“¤
    LayerPromptRequest,
    LayerPromptResponse,
    ValidationLayerPromptResponse,
)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="Spec ë¬¸ì„œ ê¸°ë°˜ ìš”êµ¬ì‚¬í•­ ìƒì„± API",
    description="RAGì™€ Perplexity AIë¥¼ ì‚¬ìš©í•œ ì§€ëŠ¥í˜• ìš”êµ¬ì‚¬í•­ ìƒì„± ì‹œìŠ¤í…œ",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS ì„¤ì • (í•„ìš”ì‹œ)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class RequirementGenerator:
    """ìš”êµ¬ì‚¬í•­ ìƒì„± ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.perplexity_client = None
    
    def _get_perplexity_client(self):
        """ì§€ì—° ë¡œë”©ìœ¼ë¡œ Perplexity í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        if self.perplexity_client is None:
            try:
                self.perplexity_client = PerplexityClient()
                logger.info("Perplexity í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.error(f"Perplexity í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                raise HTTPException(
                    status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                    detail=f"Perplexity API ì—°ê²° ì‹¤íŒ¨: {str(e)}"
                )
        return self.perplexity_client
    
    def generate_requirements(self, kb_name: str, keyword: str, validation_rounds: int = 1) -> dict:
        """ìš”êµ¬ì‚¬í•­ ìƒì„± (ë‹¤ì¤‘ ê²€ì¦ ì§€ì›)"""
        try:
            # ì§€ì‹ë² ì´ìŠ¤ ì´ˆê¸°í™” ë° í™•ì¸
            vector_store = VectorStore(kb_name)
            status = vector_store.get_status()
            
            if not status['exists'] or status['count'] == 0:
                raise HTTPException(
                    status_code=status.HTTP_404_NOT_FOUND,
                    detail=f"ì§€ì‹ë² ì´ìŠ¤ '{kb_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë¹„ì–´ìžˆìŠµë‹ˆë‹¤."
                )
            
            # ê´€ë ¨ ì²­í¬ ê²€ìƒ‰
            logger.info(f"ì§€ì‹ë² ì´ìŠ¤ '{kb_name}'ì—ì„œ í‚¤ì›Œë“œ '{keyword}' ê²€ìƒ‰ ì¤‘...")
            relevant_chunks = vector_store.search_similar_chunks(keyword)
            
            if not relevant_chunks:
                return {
                    "success": True,
                    "knowledge_base": kb_name,
                    "keyword": keyword,
                    "requirements": "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ìš”êµ¬ì‚¬í•­ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "chunks_found": 0,
                    "validation_rounds": 0,
                    "generated_at": datetime.now()
                }
            
            logger.info(f"{len(relevant_chunks)}ê°œì˜ ê´€ë ¨ ì²­í¬ ë°œê²¬")
            
            # Perplexity í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸°
            perplexity_client = self._get_perplexity_client()
            
            # ë‹¤ë‹¨ê³„ ê²€ì¦ì„ í†µí•œ ìš”êµ¬ì‚¬í•­ ìƒì„±
            logger.info(f"AI ìš”êµ¬ì‚¬í•­ ìƒì„± ë° {validation_rounds}íšŒ ê²€ì¦ ì‹œìž‘...")
            final_requirements = perplexity_client.multi_stage_validation(
                keyword, relevant_chunks, validation_rounds
            )
            
            logger.info(f"ìš”êµ¬ì‚¬í•­ ìƒì„± ì™„ë£Œ (ê²€ì¦ {validation_rounds}íšŒ)")
            
            return {
                "success": True,
                "knowledge_base": kb_name,
                "keyword": keyword,
                "requirements": final_requirements,
                "chunks_found": len(relevant_chunks),
                "validation_rounds": validation_rounds,
                "generated_at": datetime.now()
            }
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"ìš”êµ¬ì‚¬í•­ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜: {str(e)}"
            )

# ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
requirement_generator = RequirementGenerator()
workflow_engine = None

def get_workflow_engine():
    """WorkflowEngine ì§€ì—° ë¡œë”©"""
    global workflow_engine
    if workflow_engine is None:
        try:
            workflow_engine = WorkflowEngine()
            logger.info("WorkflowEngine ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"WorkflowEngine ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise HTTPException(
                status_code=503,
                detail=f"ì›Œí¬í”Œë¡œìš° ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}"
            )
    return workflow_engine

@app.get("/", tags=["Health Check"])
async def root():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return {
        "service": "Spec ë¬¸ì„œ ê¸°ë°˜ ìš”êµ¬ì‚¬í•­ ìƒì„± API",
        "status": "running",
        "version": "1.0.0",
        "timestamp": datetime.now()
    }

@app.get("/health", tags=["Health Check"])
async def health_check():
    """ìƒì„¸ í—¬ìŠ¤ì²´í¬"""
    try:
        # ì§€ì‹ë² ì´ìŠ¤ ëª©ë¡ í™•ì¸
        kb_list = Config.get_kb_list()
        
        # Perplexity API í‚¤ í™•ì¸
        api_key_status = "configured" if Config.PERPLEXITY_API_KEY else "missing"
        
        return {
            "status": "healthy",
            "perplexity_api_key": api_key_status,
            "knowledge_bases_count": len(kb_list),
            "knowledge_bases": kb_list,
            "timestamp": datetime.now()
        }
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail=f"ì„œë¹„ìŠ¤ ë¶ˆì•ˆì •: {str(e)}"
        )

@app.get("/knowledge-bases", 
         response_model=KnowledgeBaseListResponse, 
         tags=["Knowledge Base"])
async def get_knowledge_bases():
    """ì§€ì‹ë² ì´ìŠ¤ ëª©ë¡ ì¡°íšŒ"""
    try:
        kb_list = Config.get_kb_list()
        knowledge_bases = []
        
        for kb_name in kb_list:
            vector_store = VectorStore(kb_name)
            status = vector_store.get_status()
            
            knowledge_bases.append(KnowledgeBaseInfo(
                name=kb_name,
                chunk_count=status['count'],
                path=status['path'],
                exists=status['exists']
            ))
        
        return KnowledgeBaseListResponse(
            knowledge_bases=knowledge_bases,
            total_count=len(knowledge_bases)
        )
        
    except Exception as e:
        logger.error(f"ì§€ì‹ë² ì´ìŠ¤ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="ì§€ì‹ë² ì´ìŠ¤ ëª©ë¡ì„ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )

@app.get("/knowledge-bases/{kb_name}/status", 
         response_model=KnowledgeBaseInfo, 
         tags=["Knowledge Base"])
async def get_knowledge_base_status(kb_name: str):
    """íŠ¹ì • ì§€ì‹ë² ì´ìŠ¤ ìƒíƒœ ì¡°íšŒ"""
    try:
        vector_store = VectorStore(kb_name)
        status = vector_store.get_status()
        
        if not status['exists']:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"ì§€ì‹ë² ì´ìŠ¤ '{kb_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )
        
        return KnowledgeBaseInfo(
            name=kb_name,
            chunk_count=status['count'],
            path=status['path'],
            exists=status['exists']
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì§€ì‹ë² ì´ìŠ¤ ìƒíƒœ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ì§€ì‹ë² ì´ìŠ¤ ìƒíƒœë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}"
        )

@app.post("/generate-requirements", 
          response_model=RequirementResponse, 
          tags=["Requirements"])
async def generate_requirements(request: RequirementRequest):
    """ìš”êµ¬ì‚¬í•­ ìƒì„± API (ë‹¤ì¤‘ ê²€ì¦ ì§€ì›)"""
    try:
        logger.info(f"ìš”êµ¬ì‚¬í•­ ìƒì„± ìš”ì²­: KB={request.knowledge_base}, í‚¤ì›Œë“œ={request.keyword}, ê²€ì¦íšŸìˆ˜={request.validation_rounds}")
        
        result = requirement_generator.generate_requirements(
            request.knowledge_base, 
            request.keyword,
            request.validation_rounds
        )
        
        return RequirementResponse(**result)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ìš”êµ¬ì‚¬í•­ ìƒì„± API ì˜¤ë¥˜: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ìš”êµ¬ì‚¬í•­ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@app.exception_handler(HTTPException)
async def http_exception_handler(request, exc):
    """HTTP ì˜ˆì™¸ ì²˜ë¦¬"""
    return JSONResponse(
        status_code=exc.status_code,
        content=ErrorResponse(
            error_type="HTTP_ERROR",
            error_message=exc.detail
        ).dict()
    )

@app.exception_handler(Exception)
async def general_exception_handler(request, exc):
    """ì¼ë°˜ ì˜ˆì™¸ ì²˜ë¦¬"""
    logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {exc}")
    return JSONResponse(
        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
        content=ErrorResponse(
            error_type="INTERNAL_SERVER_ERROR",
            error_message="ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        ).dict()
    )

@app.get("/available-models", tags=["Models"])
async def get_available_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""
    try:
        # Perplexity Clientë¥¼ í†µí•´ ì‹¤ì œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
        perplexity_client = PerplexityClient()
        available_models = perplexity_client.get_available_models()
        
        # ê¸°ë³¸ ëª¨ë¸ ëª©ë¡ì— ì‹¤ì œ Perplexity ëª¨ë¸ë“¤ ì¶”ê°€
        models = [
            {"value": "sonar-pro", "label": "Perplexity Sonar Pro", "provider": "perplexity"},
            {"value": "sonar-medium", "label": "Perplexity Sonar Medium", "provider": "perplexity"},
        ]
        
        # ì‹¤ì œ APIì—ì„œ ê°€ì ¸ì˜¨ ëª¨ë¸ë“¤ ì¶”ê°€
        for model in available_models:
            if model not in [m["value"] for m in models]:
                models.append({
                    "value": model,
                    "label": f"Perplexity {model.replace('-', ' ').title()}",
                    "provider": "perplexity"
                })
        
        # í–¥í›„ í™•ìž¥ìš© ëª¨ë¸ë“¤
        models.extend([
            {"value": "gpt-4", "label": "OpenAI GPT-4 (Coming Soon)", "provider": "openai", "disabled": True},
            {"value": "gpt-3.5-turbo", "label": "OpenAI GPT-3.5 (Coming Soon)", "provider": "openai", "disabled": True}
        ])
        
        return {"models": models}
        
    except Exception as e:
        logger.warning(f"ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ëª¨ë¸ ëª©ë¡ ë°˜í™˜
        return {
            "models": [
                {"value": "sonar-pro", "label": "Perplexity Sonar Pro", "provider": "perplexity"},
                {"value": "sonar-medium", "label": "Perplexity Sonar Medium", "provider": "perplexity"},
                {"value": "gpt-4", "label": "OpenAI GPT-4 (Coming Soon)", "provider": "openai", "disabled": True},
                {"value": "gpt-3.5-turbo", "label": "OpenAI GPT-3.5 (Coming Soon)", "provider": "openai", "disabled": True}
            ]
        }

@app.get("/default-prompts", tags=["Prompts"])
async def get_default_prompts():
    """ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì¡°íšŒ"""
    return {
        "generation": get_default_prompt("generation"),
        "ensemble": get_default_prompt("ensemble"),
        "validation": get_default_prompt("validation")
    }

@app.post("/execute-workflow", response_model=WorkflowResponse, tags=["Workflow"])
async def execute_workflow(request: WorkflowRequest):
    """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
    try:
        logger.info(f"ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ìš”ì²­: KB={request.knowledge_base}, í‚¤ì›Œë“œ={request.keyword}")
        
        # ì§€ì‹ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì²­í¬ ê²€ìƒ‰
        vector_store = VectorStore(request.knowledge_base)
        status = vector_store.get_status()
        
        if not status['exists'] or status['count'] == 0:
            raise HTTPException(
                status_code=404,
                detail=f"ì§€ì‹ë² ì´ìŠ¤ '{request.knowledge_base}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )
        
        relevant_chunks = vector_store.search_similar_chunks(request.keyword)
        
        if not relevant_chunks:
            raise HTTPException(
                status_code=404,
                detail=f"í‚¤ì›Œë“œ '{request.keyword}'ì™€ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        workflow_engine = get_workflow_engine()
        result = workflow_engine.execute_workflow(
            request.workflow_config,
            request.keyword,
            relevant_chunks
        )
        
        return WorkflowResponse(
            success=True,
            knowledge_base=request.knowledge_base,
            keyword=request.keyword,
            final_requirements=result["final_requirements"],
            node_outputs=result["node_outputs"],
            total_execution_time=result["total_execution_time"],
            generated_at=datetime.now()
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

# ==================== ìƒˆë¡œìš´ ê°œë³„ ë…¸ë“œ ì‹¤í–‰ APIë“¤ ====================

@app.post("/search-context", response_model=SearchResponse, tags=["Workflow Steps"])
async def search_context(request: SearchRequest):
    """ì»¨í…ìŠ¤íŠ¸ ì²­í¬ ê²€ìƒ‰ (ì›Œí¬í”Œë¡œìš° 1ë‹¨ê³„)"""
    try:
        logger.info(f"ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰: KB={request.knowledge_base}, ì¿¼ë¦¬={request.query}")
        
        # ì§€ì‹ë² ì´ìŠ¤ í™•ì¸
        vector_store = VectorStore(request.knowledge_base)
        status = vector_store.get_status()
        
        if not status['exists'] or status['count'] == 0:
            raise HTTPException(
                status_code=404,
                detail=f"ì§€ì‹ë² ì´ìŠ¤ '{request.knowledge_base}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )
        
        # ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
        chunks = vector_store.search_similar_chunks(request.query, request.top_k)
        
        return SearchResponse(
            success=True,
            knowledge_base=request.knowledge_base,
            query=request.query,
            chunks=chunks,
            chunk_count=len(chunks)
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}"
        )

@app.post("/execute-node", response_model=SingleNodeResponse, tags=["Workflow Steps"])
async def execute_single_node(request: SingleNodeRequest):
    """ë‹¨ì¼ ë…¸ë“œ ì‹¤í–‰ (Generation/Ensemble/Validation Layer)"""
    try:
        logger.info(f"ë…¸ë“œ ì‹¤í–‰: {request.node_config.id} ({request.node_config.layer})")
        
        # ì»¨í…ìŠ¤íŠ¸ ì²­í¬ê°€ ì—†ìœ¼ë©´ ìžë™ìœ¼ë¡œ ê²€ìƒ‰
        context_chunks = request.context_chunks
        if not context_chunks:
            vector_store = VectorStore(request.knowledge_base)
            context_chunks = vector_store.search_similar_chunks(request.input_data)
        
        # WorkflowEngineì„ í†µí•œ ë…¸ë“œ ì‹¤í–‰
        workflow_engine = get_workflow_engine()
        node_output = workflow_engine.execute_node(
            request.node_config, 
            request.input_data, 
            context_chunks
        )
        
        return SingleNodeResponse(
            success=True,
            node_output=node_output,
            context_chunks_used=context_chunks
        )
        
    except Exception as e:
        logger.error(f"ë…¸ë“œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ë…¸ë“œ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}"
        )

@app.post("/execute-ensemble", response_model=SingleNodeResponse, tags=["Workflow Steps"])
async def execute_ensemble_node(request: EnsembleRequest):
    """ì•™ìƒë¸” ë ˆì´ì–´ ì‹¤í–‰ (ì—¬ëŸ¬ Generation ê²°ê³¼ í†µí•©)"""
    try:
        logger.info(f"ì•™ìƒë¸” ë…¸ë“œ ì‹¤í–‰: {request.ensemble_node.id}")
        
        # Generation ê²°ê³¼ë“¤ì„ í•˜ë‚˜ì˜ ìž…ë ¥ìœ¼ë¡œ ê²°í•©
        combined_input = "\n\n=== Generation Layer ê²°ê³¼ë“¤ ===\n\n" + "\n\n".join(
            f"Generation {i+1}:\n{result}" 
            for i, result in enumerate(request.generation_results)
        )
        
        # ì»¨í…ìŠ¤íŠ¸ ì²­í¬ ì¤€ë¹„
        context_chunks = request.context_chunks or []
        
        # ì•™ìƒë¸” ë…¸ë“œ ì‹¤í–‰
        workflow_engine = get_workflow_engine()
        node_output = workflow_engine.execute_node(
            request.ensemble_node,
            combined_input,
            context_chunks
        )
        
        return SingleNodeResponse(
            success=True,
            node_output=node_output,
            context_chunks_used=context_chunks
        )
        
    except Exception as e:
        logger.error(f"ì•™ìƒë¸” ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ì•™ìƒë¸” ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}"
        )

@app.post("/execute-validation", response_model=ValidationResponse, tags=["Workflow Steps"])
async def execute_validation_node(request: ValidationRequest):
    """ê²€ì¦ ë ˆì´ì–´ ì‹¤í–‰ (ë³€ê²½ì‚¬í•­ ì¶”ì  í¬í•¨)"""
    try:
        logger.info(f"ê²€ì¦ ë…¸ë“œ ì‹¤í–‰: {request.validation_node.id}")
        
        # ì»¨í…ìŠ¤íŠ¸ ì²­í¬ ì¤€ë¹„
        context_chunks = request.context_chunks or []
        
        # ê²€ì¦ ë…¸ë“œ ì‹¤í–‰
        workflow_engine = get_workflow_engine()
        node_output = workflow_engine.execute_node(
            request.validation_node,
            request.input_requirements,
            context_chunks
        )
        
        # ë³€ê²½ì‚¬í•­ ë¶„ì„ (ê°„ë‹¨í•œ êµ¬í˜„ - ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë¹„êµ í•„ìš”)
        changes = analyze_validation_changes(
            request.input_requirements, 
            node_output.requirements
        )
        
        return ValidationResponse(
            success=True,
            node_output=node_output,
            changes=changes,
            context_chunks_used=context_chunks
        )
        
    except Exception as e:
        logger.error(f"ê²€ì¦ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ê²€ì¦ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}"
        )

def analyze_validation_changes(input_requirements: str, output_requirements: str) -> List[ValidationChange]:
    """ê²€ì¦ ê³¼ì •ì—ì„œ ë°œìƒí•œ ë³€ê²½ì‚¬í•­ ë¶„ì„"""
    changes = []
    
    try:
        # ê°„ë‹¨í•œ ë³€ê²½ì‚¬í•­ ê°ì§€ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ êµ¬í˜„ í•„ìš”)
        input_lines = input_requirements.split('\n')
        output_lines = output_requirements.split('\n')
        
        # í…Œì´ë¸” í–‰ë§Œ ì¶”ì¶œ (|ë¡œ ì‹œìž‘í•˜ëŠ” í–‰ë“¤)
        input_rows = [line.strip() for line in input_lines if line.strip().startswith('|') and '---' not in line]
        output_rows = [line.strip() for line in output_lines if line.strip().startswith('|') and '---' not in line]
        
        # í—¤ë” ì œì™¸
        if input_rows: input_rows = input_rows[1:]
        if output_rows: output_rows = output_rows[1:]
        
        # ê¸¸ì´ê°€ ë‹¤ë¥´ë©´ ìš”êµ¬ì‚¬í•­ì´ ì¶”ê°€/ì‚­ì œëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
        if len(output_rows) > len(input_rows):
            for i in range(len(input_rows), len(output_rows)):
                if i < len(output_rows):
                    changes.append(ValidationChange(
                        requirement_id=f"REQ-{i+1:03d}",
                        original="",
                        modified=output_rows[i],
                        change_type="added",
                        reason="ê²€ì¦ ê³¼ì •ì—ì„œ ì¶”ê°€ëœ ìš”êµ¬ì‚¬í•­"
                    ))
        elif len(output_rows) < len(input_rows):
            for i in range(len(output_rows), len(input_rows)):
                changes.append(ValidationChange(
                    requirement_id=f"REQ-{i+1:03d}",
                    original=input_rows[i] if i < len(input_rows) else "",
                    modified="",
                    change_type="removed",
                    reason="ê²€ì¦ ê³¼ì •ì—ì„œ ì œê±°ëœ ìš”êµ¬ì‚¬í•­"
                ))
        
        # ë‚´ìš©ì´ ë‹¤ë¥¸ í–‰ë“¤ ì°¾ê¸°
        min_len = min(len(input_rows), len(output_rows))
        for i in range(min_len):
            if input_rows[i] != output_rows[i]:
                changes.append(ValidationChange(
                    requirement_id=f"REQ-{i+1:03d}",
                    original=input_rows[i],
                    modified=output_rows[i],
                    change_type="modified",
                    reason="ê²€ì¦ ê³¼ì •ì—ì„œ ìˆ˜ì •ëœ ìš”êµ¬ì‚¬í•­"
                ))
                
    except Exception as e:
        logger.warning(f"ë³€ê²½ì‚¬í•­ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ì‹œ ì „ì²´ê°€ ë³€ê²½ëœ ê²ƒìœ¼ë¡œ ì²˜ë¦¬
        changes.append(ValidationChange(
            requirement_id="ALL",
            original=input_requirements[:100] + "...",
            modified=output_requirements[:100] + "...",
            change_type="modified",
            reason="ì „ì²´ ìš”êµ¬ì‚¬í•­ì´ ê²€ì¦ ê³¼ì •ì—ì„œ ìž¬êµ¬ì„±ë¨"
        ))
    
    return changes

# ==================== ìƒˆë¡œìš´ Layerë³„ ì‹¤í–‰ API ====================

@app.post("/execute-generation-layer", response_model=LayerExecutionResponse)
async def execute_generation_layer(request: LayerExecutionRequest):
    """Generation Layer ì „ì²´ ì‹¤í–‰"""
    start_time = time.time()
    
    try:
        logger.info(f"Generation Layer ì‹¤í–‰ ì‹œìž‘: {request.knowledge_base}")
        
        # ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ (ì—†ìœ¼ë©´ ìƒˆë¡œ ê²€ìƒ‰)
        if not request.context_chunks:
            vector_store = VectorStore(request.knowledge_base)
            context_chunks = vector_store.search_similar_chunks(request.input_data, Config.SEARCH_TOP_K)
        else:
            context_chunks = request.context_chunks
        
        outputs = []
        failed_nodes = []
        
        # ê° Generation ë…¸ë“œ ë³‘ë ¬ ì‹¤í–‰
        for node in request.nodes:
            try:
                # Perplexity í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
                perplexity = PerplexityClient()
                
                # í”„ë¡¬í”„íŠ¸ ìƒì„±
                context_text = "\n".join(context_chunks)
                prompt = f"""
{node.prompt}

ì°¸ê³  ë¬¸ì„œ:
{context_text}

í‚¤ì›Œë“œ: {request.input_data}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì ì¸ ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
"""
                
                # AI ëª¨ë¸ ì‹¤í–‰
                node_start = time.time()
                ai_response = perplexity.generate_requirements(prompt, node.model_type)
                node_time = time.time() - node_start
                
                # ê²°ê³¼ ì €ìž¥
                outputs.append(NodeOutput(
                    node_id=node.id,
                    model_type=node.model_type,
                    requirements=ai_response,
                    execution_time=node_time
                ))
                
            except Exception as e:
                logger.error(f"ë…¸ë“œ {node.id} ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                failed_nodes.append(node.id)
        
        # ê²°ê³¼ í†µí•© (ê°„ë‹¨í•œ ê²°í•©)
        if outputs:
            combined_result = "\n\n".join([output.requirements for output in outputs])
        else:
            combined_result = ""
        
        execution_time = time.time() - start_time
        
        return LayerExecutionResponse(
            success=len(outputs) > 0,
            layer_type="generation",
            knowledge_base=request.knowledge_base,
            input_data=request.input_data,
            outputs=outputs,
            combined_result=combined_result,
            failed_nodes=failed_nodes,
            execution_time=execution_time,
            context_chunks_used=context_chunks
        )
        
    except Exception as e:
        logger.error(f"Generation Layer ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Generation Layer ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@app.post("/execute-ensemble-layer", response_model=LayerExecutionResponse)
async def execute_ensemble_layer(request: LayerExecutionRequest):
    """Ensemble Layer ì‹¤í–‰"""
    start_time = time.time()
    
    try:
        logger.info(f"Ensemble Layer ì‹¤í–‰ ì‹œìž‘: {request.knowledge_base}")
        
        if not request.nodes or len(request.nodes) != 1:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Ensemble LayerëŠ” ì •í™•ížˆ í•˜ë‚˜ì˜ ë…¸ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤"
            )
        
        node = request.nodes[0]
        context_chunks = request.context_chunks or []
        
        # Perplexity í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        perplexity = PerplexityClient()
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        context_text = "\n".join(context_chunks)
        prompt = f"""
{node.prompt}

ì°¸ê³  ë¬¸ì„œ:
{context_text}

ì—¬ëŸ¬ AI ëª¨ë¸ì´ ìƒì„±í•œ ìš”êµ¬ì‚¬í•­ë“¤:
{request.input_data}

ìœ„ ìš”êµ¬ì‚¬í•­ë“¤ì„ ì¢…í•©í•˜ì—¬ ì¼ê´€ì„± ìžˆê³  ì™„ì „í•œ ìš”êµ¬ì‚¬í•­ìœ¼ë¡œ í†µí•©í•´ì£¼ì„¸ìš”.
"""
        
        # AI ëª¨ë¸ ì‹¤í–‰
        node_start = time.time()
        ai_response = perplexity.generate_requirements(prompt, node.model_type)
        node_time = time.time() - node_start
        
        # ê²°ê³¼ ì €ìž¥
        output = NodeOutput(
            node_id=node.id,
            model_type=node.model_type,
            requirements=ai_response,
            execution_time=node_time
        )
        
        execution_time = time.time() - start_time
        
        return LayerExecutionResponse(
            success=True,
            layer_type="ensemble",
            knowledge_base=request.knowledge_base,
            input_data=request.input_data,
            outputs=[output],
            combined_result=ai_response,
            failed_nodes=[],
            execution_time=execution_time,
            context_chunks_used=context_chunks
        )
        
    except Exception as e:
        logger.error(f"Ensemble Layer ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Ensemble Layer ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@app.post("/execute-validation-layer", response_model=ValidationLayerResponse)
async def execute_validation_layer(request: LayerExecutionRequest):
    """Validation Layer ì‹¤í–‰"""
    start_time = time.time()
    
    try:
        logger.info(f"Validation Layer ì‹¤í–‰ ì‹œìž‘: {request.knowledge_base}")
        
        context_chunks = request.context_chunks or []
        outputs = []
        failed_nodes = []
        validation_changes = []
        filtered_requirements = []
        
        current_requirements = request.input_data
        
        # ê° Validation ë…¸ë“œ ìˆœì°¨ ì‹¤í–‰
        for i, node in enumerate(request.nodes):
            try:
                # Perplexity í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
                perplexity = PerplexityClient()
                
                # í”„ë¡¬í”„íŠ¸ ìƒì„±
                context_text = "\n".join(context_chunks)
                prompt = f"""
{node.prompt}

ì°¸ê³  ë¬¸ì„œ:
{context_text}

í˜„ìž¬ ìš”êµ¬ì‚¬í•­:
{current_requirements}

ìœ„ ìš”êµ¬ì‚¬í•­ì„ ê²€ì¦í•˜ê³  ê°œì„ í•´ì£¼ì„¸ìš”.
"""
                
                # AI ëª¨ë¸ ì‹¤í–‰
                node_start = time.time()
                ai_response = perplexity.generate_requirements(prompt, node.model_type)
                node_time = time.time() - node_start
                
                # ë³€ê²½ì‚¬í•­ ë¶„ì„
                changes = analyze_validation_changes(current_requirements, ai_response)
                validation_changes.extend(changes)
                
                # í•„í„°ë§ëœ ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ (ì œê±°ëœ ê²ƒë“¤)
                for change in changes:
                    if change.change_type == "removed":
                        filtered_requirements.append(change.original)
                
                # ê²°ê³¼ ì €ìž¥
                outputs.append(NodeOutput(
                    node_id=node.id,
                    model_type=node.model_type,
                    requirements=ai_response,
                    execution_time=node_time
                ))
                
                # ë‹¤ìŒ ë…¸ë“œë¥¼ ìœ„í•´ ê²°ê³¼ ì—…ë°ì´íŠ¸
                current_requirements = ai_response
                
            except Exception as e:
                logger.error(f"Validation ë…¸ë“œ {node.id} ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                failed_nodes.append(node.id)
        
        execution_time = time.time() - start_time
        
        return ValidationLayerResponse(
            success=len(outputs) > 0,
            layer_type="validation",
            knowledge_base=request.knowledge_base,
            input_data=request.input_data,
            outputs=outputs,
            combined_result=current_requirements,
            failed_nodes=failed_nodes,
            execution_time=execution_time,
            context_chunks_used=context_chunks,
            filtered_requirements=filtered_requirements,
            validation_changes=validation_changes
        )
        
    except Exception as e:
        logger.error(f"Validation Layer ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Validation Layer ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

def main():
    """API ì„œë²„ ì‹¤í–‰"""
    print("ðŸš€ Spec ë¬¸ì„œ ê¸°ë°˜ ìš”êµ¬ì‚¬í•­ ìƒì„± API ì„œë²„ ì‹œìž‘")
    print("=" * 60)
    
    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    if not Config.PERPLEXITY_API_KEY:
        print("âŒ PERPLEXITY_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        print("ðŸ’¡ .env íŒŒì¼ì„ í™•ì¸í•˜ê±°ë‚˜ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        return
    
    print("âœ… í™˜ê²½ ë³€ìˆ˜ í™•ì¸ ì™„ë£Œ")
    print("ðŸ“– API ë¬¸ì„œ: http://localhost:8000/docs")
    print("ðŸ”„ ReDoc: http://localhost:8000/redoc")
    print("â¤ï¸ Health Check: http://localhost:8000/health")
    print("=" * 60)
    
    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=8000,
        reload=True,  # ê°œë°œ ì¤‘ì—ë§Œ ì‚¬ìš©
        log_level="info"
    )

# ==================== Layerë³„ í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ ì—”ë“œí¬ì¸íŠ¸ë“¤ ====================

@app.post("/execute-layer-prompt", response_model=LayerPromptResponse)
async def execute_layer_prompt(request: LayerPromptRequest):
    """
    Layerë³„ í”„ë¡¬í”„íŠ¸ë¡œ ì‹¤í–‰ (ëª¨ë“  Layer íƒ€ìž… ì§€ì›)
    """
    try:
        start_time = time.time()
        logger.info(f"{request.layer_type} Layer í”„ë¡¬í”„íŠ¸ ì‹¤í–‰ ì‹œìž‘: {request.knowledge_base}")
        
        # ì›Œí¬í”Œë¡œìš° ì—”ì§„ ì´ˆê¸°í™”
        engine = WorkflowEngine()
        
        # ìš”ì²­ì—ì„œ ì „ë‹¬ë°›ì€ ë…¸ë“œë“¤ ì‚¬ìš©
        nodes = request.nodes
        
        # ë…¸ë“œë“¤ì´ ë¹„ì–´ìžˆìœ¼ë©´ ê¸°ë³¸ ë…¸ë“œ ìƒì„± (ë°±ì—…)
        if not nodes:
            if request.layer_type == "generation":
                nodes = [
                    NodeConfig(
                        id=f"gen_sonar_pro_{int(time.time())}",
                        model_type=ModelType.PERPLEXITY_SONAR_PRO,
                        prompt=request.prompt,
                        layer="generation",
                        position={"x": 100, "y": 100}
                    )
                ]
            elif request.layer_type == "ensemble":
                nodes = [
                    NodeConfig(
                        id=f"ens_sonar_pro_{int(time.time())}",
                        model_type=ModelType.PERPLEXITY_SONAR_PRO,
                        prompt=request.prompt,
                        layer="ensemble",
                        position={"x": 300, "y": 200}
                    )
                ]
            elif request.layer_type == "validation":
                nodes = [
                    NodeConfig(
                        id=f"val_sonar_pro_{int(time.time())}",
                        model_type=ModelType.PERPLEXITY_SONAR_PRO,
                        prompt=request.prompt,
                        layer="validation",
                        position={"x": 500, "y": 100}
                    )
                ]
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” Layer íƒ€ìž…: {request.layer_type}")
        
        # ëª¨ë“  ë…¸ë“œì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ìš”ì²­ëœ í”„ë¡¬í”„íŠ¸ë¡œ ì—…ë°ì´íŠ¸
        for node in nodes:
            node.prompt = request.prompt
        
        # Validation Layerë¥¼ ìœ„í•œ ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
        enhanced_context_chunks = request.context_chunks or []
        if request.layer_type == "validation" and request.knowledge_base:
            try:
                # Validationì„ ìœ„í•´ ë” ë§Žì€ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
                vector_store = VectorStore(request.knowledge_base)
                
                # ìž…ë ¥ ë°ì´í„°ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œí•˜ì—¬ ì¶”ê°€ ê²€ìƒ‰
                import re
                # í…Œì´ë¸”ì—ì„œ ìš”êµ¬ì‚¬í•­ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                requirement_texts = re.findall(r'\|\s*[^|]+\s*\|\s*([^|]+)\s*\|', request.input_data)
                search_terms = []
                
                # ìš”êµ¬ì‚¬í•­ì—ì„œ ì¤‘ìš”í•œ í‚¤ì›Œë“œë“¤ ì¶”ì¶œ
                for req_text in requirement_texts[:3]:  # ì²˜ìŒ 3ê°œ ìš”êµ¬ì‚¬í•­ë§Œ ì‚¬ìš©
                    if req_text.strip() and len(req_text.strip()) > 10:
                        search_terms.append(req_text.strip()[:50])  # ì²˜ìŒ 50ìžë§Œ ì‚¬ìš©
                
                # ê° ê²€ìƒ‰ì–´ë¡œ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
                all_chunks = set(enhanced_context_chunks)
                for term in search_terms:
                    if term:
                        chunks = vector_store.search_similar_chunks(term, top_k=5)
                        all_chunks.update(chunks)
                
                enhanced_context_chunks = list(all_chunks)[:15]  # ìµœëŒ€ 15ê°œ ì²­í¬
                logger.info(f"Validationì„ ìœ„í•œ í™•ìž¥ ì»¨í…ìŠ¤íŠ¸: {len(enhanced_context_chunks)}ê°œ ì²­í¬")
                
            except Exception as e:
                logger.warning(f"Validation ì»¨í…ìŠ¤íŠ¸ í™•ìž¥ ì‹¤íŒ¨: {e}")
                # ì‹¤íŒ¨í•´ë„ ê¸°ì¡´ ì»¨í…ìŠ¤íŠ¸ë¡œ ì§„í–‰
        
        # ê° ë…¸ë“œ ê°œë³„ ì‹¤í–‰
        outputs = []
        failed_nodes = []
        validation_steps = []
        current_input = request.input_data
        
        if request.layer_type == "validation":
            # Validation Layer: ë…¸ë“œë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ì—¬ ê²€ì¦ ê³¼ì • ì§„í–‰
            for i, node in enumerate(nodes):
                try:
                    logger.info(f"Validation ë…¸ë“œ {i+1}/{len(nodes)} ì‹¤í–‰ ì¤‘: {node.id}")
                    node_output = engine.execute_node(node, current_input, enhanced_context_chunks)
                    outputs.append(node_output)
                    outputs.append(node_output)
                    
                    # ê²€ì¦ ë‹¨ê³„ ê¸°ë¡
                    validation_step = {
                        "step": i + 1,
                        "node_id": node.id,
                        "model_type": node.model_type.value,
                        "input": current_input[:200] + "..." if len(current_input) > 200 else current_input,
                        "output": node_output.requirements[:200] + "..." if len(node_output.requirements) > 200 else node_output.requirements,
                        "execution_time": node_output.execution_time
                    }
                    validation_steps.append(validation_step)
                    
                    # ë‹¤ìŒ ë…¸ë“œë¥¼ ìœ„í•´ í˜„ìž¬ ì¶œë ¥ì„ ìž…ë ¥ìœ¼ë¡œ ì„¤ì •
                    current_input = node_output.requirements
                    
                except Exception as e:
                    failed_nodes.append(node.id)
                    logger.error(f"Validation ë…¸ë“œ {node.id} ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
        else:
            # Generation/Ensemble Layer: ë³‘ë ¬ ì‹¤í–‰ (ê¸°ì¡´ ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©)
            for node in nodes:
                try:
                    node_output = engine.execute_node(node, request.input_data, request.context_chunks or [])
                    outputs.append(node_output)
                except Exception as e:
                    failed_nodes.append(node.id)
                    logger.error(f"ë…¸ë“œ {node.id} ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
        
        # ê²°ê³¼ ì·¨í•©
        if outputs:
            if request.layer_type == "validation":
                # Validation: ë§ˆì§€ë§‰ ë…¸ë“œì˜ ì¶œë ¥ì´ ìµœì¢… ê²°ê³¼
                combined_result = outputs[-1].requirements if outputs else ""
                final_validated_result = combined_result
            else:
                # Generation/Ensemble: ëª¨ë“  ì¶œë ¥ì„ ê²°í•©
                combined_result = "\n\n".join([output.requirements for output in outputs])
                final_validated_result = ""
        else:
            combined_result = "ëª¨ë“  ë…¸ë“œ ì‹¤í–‰ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            final_validated_result = ""
        
        execution_time = (time.time() - start_time) * 1000
        
        if request.layer_type == "validation":
            # ìš”êµ¬ì‚¬í•­ í•„í„°ë§ ë° ë¶„ì„
            filtered_requirements = []
            removed_requirements = []
            
            if outputs:
                # ë§ˆì§€ë§‰ ê²€ì¦ ê²°ê³¼ì—ì„œ ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ
                final_output = outputs[-1].requirements
                import re
                
                # í•„í„°ë§ëœ ìš”êµ¬ì‚¬í•­ í‘œ ì¶”ì¶œ
                filtered_table_match = re.search(r'\*\*í•„í„°ë§ëœ ìš”êµ¬ì‚¬í•­ í‘œ:\*\*(.*?)(?=\*\*ì œê±°ëœ ìš”êµ¬ì‚¬í•­:|\Z)', final_output, re.DOTALL)
                if filtered_table_match:
                    filtered_table = filtered_table_match.group(1).strip()
                    table_rows = re.findall(r'\|\s*([^|]+)\s*\|\s*([^|]+)\s*\|\s*([^|]+)\s*\|\s*([^|]+)\s*\|', filtered_table)
                    for row in table_rows:
                        if row[0].strip() and not row[0].strip().startswith('ID') and not row[0].strip().startswith('-'):
                            req_id = row[0].strip()
                            req_text = row[1].strip()
                            source = row[2].strip()
                            status = row[3].strip()
                            if req_id and req_text:
                                filtered_requirements.append(f"{req_id}: {req_text} (ì¶œì²˜: {source}, ìƒíƒœ: {status})")
                
                # ì œê±°ëœ ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ
                removed_match = re.search(r'\*\*ì œê±°ëœ ìš”êµ¬ì‚¬í•­:\*\*(.*?)$', final_output, re.DOTALL)
                if removed_match:
                    removed_section = removed_match.group(1).strip()
                    # ì œê±°ëœ ìš”êµ¬ì‚¬í•­ íŒŒì‹± (ê°„ë‹¨í•œ í˜•íƒœ)
                    removed_lines = [line.strip() for line in removed_section.split('\n') if line.strip() and not line.strip().startswith('(')]
                    for line in removed_lines:
                        if line and '-' in line:
                            removed_requirements.append(line)
                
                # ì›ë³¸ ìš”êµ¬ì‚¬í•­ê³¼ ë¹„êµí•˜ì—¬ í•„í„°ë§ í†µê³„ ìƒì„±
                original_input = request.input_data
                original_table_rows = re.findall(r'\|\s*([^|]+)\s*\|\s*([^|]+)\s*\|', original_input)
                original_count = len([row for row in original_table_rows if row[0].strip() and not row[0].strip().startswith('ID') and not row[0].strip().startswith('-')])
                filtered_count = len(filtered_requirements)
                
                logger.info(f"Validation í•„í„°ë§ ê²°ê³¼: ì›ë³¸ {original_count}ê°œ â†’ í•„í„°ë§ í›„ {filtered_count}ê°œ (ì œê±°: {original_count - filtered_count}ê°œ)")
            
            return ValidationLayerPromptResponse(
                success=len(outputs) > 0,
                layer_type=request.layer_type,
                knowledge_base=request.knowledge_base,
                input_data=request.input_data,
                layer_prompt=request.prompt,
                outputs=outputs,
                combined_result=combined_result,
                failed_nodes=failed_nodes,
                execution_time=execution_time,
                context_chunks_used=enhanced_context_chunks,
                updated_input=combined_result,  # Validationì˜ ê²½ìš° ê²°ê³¼ê°€ ë‹¤ìŒ ìž…ë ¥
                filtered_requirements=filtered_requirements,
                validation_changes=removed_requirements,  # ì œê±°ëœ ìš”êµ¬ì‚¬í•­ì„ ë³€ê²½ì‚¬í•­ìœ¼ë¡œ í™œìš©
                final_validated_result=final_validated_result,
                validation_steps=validation_steps
            )
        else:
            return LayerPromptResponse(
                success=len(outputs) > 0,
                layer_type=request.layer_type,
                knowledge_base=request.knowledge_base,
                input_data=request.input_data,
                layer_prompt=request.prompt,
                outputs=outputs,
                combined_result=combined_result,
                failed_nodes=failed_nodes,
                execution_time=execution_time,
                context_chunks_used=request.context_chunks or [],
                updated_input=combined_result
            )
            
    except Exception as e:
        logger.error(f"{request.layer_type} Layer í”„ë¡¬í”„íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"{request.layer_type} Layer í”„ë¡¬í”„íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")

if __name__ == "__main__":
    main()
