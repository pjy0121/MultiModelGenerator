import chromadb
import os
import threading
from typing import List, Dict, Optional
from ..core.config import VECTOR_DB_CONFIG
from ..core.utils import get_kb_path
from ..core.models import SearchIntensity
from .rerank import ReRanker

# ChromaDBManager í´ë˜ìŠ¤ ì œê±°ë¨ - ê° VectorStore ì¸ìŠ¤í„´ìŠ¤ê°€ ë…ë¦½ì ì¸ í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©

class VectorStore:
    def __init__(self, kb_name: str):
        self.embedding_function = chromadb.utils.embedding_functions.SentenceTransformerEmbeddingFunction(
            model_name=VECTOR_DB_CONFIG["embedding_model"])

        self.kb_name = kb_name
        self.db_path = get_kb_path(kb_name)
        
        # ì§€ì—° ì´ˆê¸°í™” - ì‹¤ì œ ì‚¬ìš©í•  ë•Œë§Œ ChromaDB íŒŒì¼ ì ‘ê·¼
        self.client = None
        self.collection = None
        
    def get_collection(self):
        """ì»¬ë ‰ì…˜ì„ ì§€ì—° ì´ˆê¸°í™”ë¡œ ë°˜í™˜ (ë™ì‹œì„± ë¬¸ì œ í•´ê²°ëœ ë²„ì „)"""
        if self.collection is None:
            # ê° VectorStore ì¸ìŠ¤í„´ìŠ¤ë§ˆë‹¤ ë…ë¦½ì ì¸ ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„±
            if self.client is None:
                os.makedirs(self.db_path, exist_ok=True)
                # ë™ì‹œ ì ‘ê·¼ ì‹œ ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•´ ë°ì´í„°ë² ì´ìŠ¤ ì˜¤í”ˆ ì‹œë„
                max_retries = 3
                for attempt in range(max_retries):
                    try:
                        self.client = chromadb.PersistentClient(path=self.db_path)
                        break
                    except Exception as e:
                        if attempt < max_retries - 1:
                            print(f"âš ï¸ ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹œë„ {attempt + 1} ì‹¤íŒ¨ (KB: {self.kb_name}): {e}")
                            import time
                            time.sleep(0.1 + attempt * 0.1)  # ì ì§„ì  ë°±ì˜¤í”„
                        else:
                            raise e
            
            # ì»¬ë ‰ì…˜ ì ‘ê·¼ë„ ì¬ì‹œë„ ë¡œì§ ì ìš©
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    self.collection = self.client.get_or_create_collection(
                        name="spec_documents",
                        metadata={"hnsw:space": "cosine"},
                        embedding_function=self.embedding_function
                    )
                    break
                except Exception as e:
                    if attempt < max_retries - 1:
                        print(f"âš ï¸ ì»¬ë ‰ì…˜ ì ‘ê·¼ ì‹œë„ {attempt + 1} ì‹¤íŒ¨ (KB: {self.kb_name}): {e}")
                        import time
                        time.sleep(0.2 + attempt * 0.1)  # ì ì§„ì  ë°±ì˜¤í”„
                        # í´ë¼ì´ì–¸íŠ¸ ì¬ìƒì„±
                        self.client = chromadb.PersistentClient(path=self.db_path)
                    else:
                        raise e
        
        return self.collection

    def store_chunks(self, chunks: List[Dict]) -> None:
        """ì²­í¬ë“¤ì„ ë²¡í„° DBì— ì €ì¥"""
        print(f"ğŸ’¾ ì§€ì‹ ë² ì´ìŠ¤ '{self.kb_name}'ì— {len(chunks)}ê°œ ì²­í¬ ì €ì¥ ì¤‘...")
        
        # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ìƒˆë¡œ ì €ì¥í•˜ëŠ” ê²½ìš°)
        try:
            self.collection.delete()
            self.collection = self.get_collection()
        except:
            pass
        
        ids = [f"chunk_{chunk['id']}" for chunk in chunks]
        documents = [chunk['content'] for chunk in chunks]
        embeddings = [chunk['embedding'] for chunk in chunks]
        metadatas = [{'length': chunk['length'], 'chunk_id': chunk['id']} for chunk in chunks]
        
        # ë°°ì¹˜ í¬ê¸°ë¡œ ë‚˜ëˆ„ì–´ ì €ì¥ (ChromaDB ì œí•œ)
        batch_size = 100
        for i in range(0, len(chunks), batch_size):
            end_idx = min(i + batch_size, len(chunks))
            
            self.get_collection().add(
                ids=ids[i:end_idx],
                documents=documents[i:end_idx],
                embeddings=embeddings[i:end_idx],
                metadatas=metadatas[i:end_idx]
            )
        
        print(f"âœ… ì§€ì‹ ë² ì´ìŠ¤ '{self.kb_name}' ì €ì¥ ì™„ë£Œ!")

    async def _search_initial_chunks(self, query: str, top_k: int) -> List[str]:
        """ì´ˆê¸° ë²¡í„° ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ë‚´ë¶€ í—¬í¼ í•¨ìˆ˜ (ë¹„ë™ê¸° ê°œì„ ëœ ë²„ì „)"""
        print(f"ğŸ” ì§€ì‹ ë² ì´ìŠ¤ '{self.kb_name}'ì—ì„œ í‚¤ì›Œë“œ '{query}' ì´ˆê¸° ê²€ìƒ‰ ì¤‘... (top_k={top_k})")
        
        try:
            # ë¹„ë™ê¸°ë¡œ ì»´ë ‰ì…˜ ì ‘ê·¼
            import asyncio
            collection = await asyncio.get_event_loop().run_in_executor(
                None, self.get_collection
            )
            
            # ì¹´ìš´íŠ¸ ì¡°íšŒë„ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬
            collection_count = await asyncio.get_event_loop().run_in_executor(
                None, collection.count
            )
            
            if collection_count == 0:
                print("âŒ ì§€ì‹ ë² ì´ìŠ¤ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                return []
            
            actual_top_k = min(top_k, collection_count)
            
            # ë²¡í„° ê²€ìƒ‰ë„ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬
            results = await asyncio.get_event_loop().run_in_executor(
                None, 
                lambda: collection.query(
                    query_texts=[query],
                    n_results=actual_top_k,
                    include=['documents', 'distances']
                )
            )
            
            if not results['documents'] or not results['documents'][0]:
                print("âŒ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return []

            initial_chunks = results['documents'][0]
            distances = results['distances'][0] if results['distances'] else []
            
            filtered_chunks = [
                chunk for chunk, distance in zip(initial_chunks, distances)
                if distance <= VECTOR_DB_CONFIG["similarity_threshold"]
            ]
            
            print(f"ğŸ“š 1ì°¨ í•„í„°ë§ í›„ {len(filtered_chunks)}ê°œ ê´€ë ¨ ì²­í¬ ë°œê²¬.")
            return filtered_chunks

        except Exception as e:
            print(f"âš ï¸ ì´ˆê¸° ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []

    async def search(
        self,
        query: str,
        search_intensity: str,
        rerank_info: Optional[Dict[str, str]] = None
    ) -> List[str]:
        """
        í†µí•© ê²€ìƒ‰ ë©”ì„œë“œ - ê³µí†µ ë¡œì§ì„ í•˜ë‚˜ë¡œ í†µí•©
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            search_intensity: ê²€ìƒ‰ ê°•ë„
            rerank_info: rerank ì •ë³´ {"provider": "openai", "model": "gpt-3.5-turbo"}
        """
        # ê³µí†µ: ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ì„¤ì •
        search_params = SearchIntensity.get_search_params(search_intensity)

        top_k_init = search_params["init"]
        
        # rerank ì‚¬ìš© ì‹œì—ëŠ” ë” ë§ì€ ì´ˆê¸° ê²€ìƒ‰, ì•„ë‹ˆë©´ finalê³¼ ë™ì¼
        if rerank_info:
            initial_chunks = await self._search_initial_chunks(query, top_k_init)
            
            if not initial_chunks:
                return []
            
            top_k_final = search_params["final"]
            try:
                reranker = ReRanker(provider=rerank_info["provider"], model=rerank_info["model"])
                reranked_chunks = await reranker.rerank_documents(query, initial_chunks, top_k_final)
                return reranked_chunks
            except Exception as e:
                print(f"âš ï¸ ì¬ì •ë ¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼ì˜ ì¼ë¶€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
                return initial_chunks[:top_k_final]
        else:
            initial_chunks = await self._search_initial_chunks(query, top_k_init)
            return initial_chunks
    
    async def get_status(self) -> dict:
        """ì§€ì‹ ë² ì´ìŠ¤ ìƒíƒœ ì •ë³´ ë°˜í™˜ (ë¹„ë™ê¸° ê°œì„ ëœ ë²„ì „)"""
        try:
            import asyncio
            collection = await asyncio.get_event_loop().run_in_executor(
                None, self.get_collection
            )
            count = await asyncio.get_event_loop().run_in_executor(
                None, collection.count
            )
            return {
                'exists': True,
                'count': count,
                'path': self.db_path,
                'name': self.kb_name
            }
        except:
            return {
                'exists': False,
                'count': 0,
                'path': self.db_path,
                'name': self.kb_name
            }
    
    def get_knowledge_bases(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì§€ì‹ ë² ì´ìŠ¤ ëª©ë¡ ë°˜í™˜"""
        try:
            kb_base_path = os.path.join(os.path.dirname(__file__), '..', '..', 'knowledge_bases')
            if not os.path.exists(kb_base_path):
                return []
            
            knowledge_bases = []
            for item in os.listdir(kb_base_path):
                item_path = os.path.join(kb_base_path, item)
                if os.path.isdir(item_path):
                    knowledge_bases.append(item)
            
            return knowledge_bases
            
        except Exception as e:
            print(f"ì§€ì‹ ë² ì´ìŠ¤ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    async def get_knowledge_base_info(self) -> Dict:
        """ì§€ì‹ ë² ì´ìŠ¤ ìƒì„¸ ì •ë³´ ë°˜í™˜ (ChromaDB íŒŒì¼ ì ‘ê·¼ ìµœì†Œí™”)"""
        import asyncio
        
        def get_info_without_chromadb():
            """ChromaDB íŒŒì¼ì— ì ‘ê·¼í•˜ì§€ ì•Šê³  ê¸°ë³¸ ì •ë³´ë§Œ ë°˜í™˜"""
            # ë””ë ‰í† ë¦¬ ì¡´ì¬ ì—¬ë¶€ë§Œ í™•ì¸
            exists = os.path.exists(self.db_path)
            
            # íŒŒì¼ ê°œìˆ˜ë¡œ ëŒ€ëµì ì¸ chunk ìˆ˜ ì¶”ì • (ChromaDB ì ‘ê·¼ ì—†ì´)
            estimated_count = 0
            if exists:
                try:
                    # ChromaDB ë””ë ‰í† ë¦¬ ë‚´ íŒŒì¼ë“¤ì˜ ê°œìˆ˜ë¡œ ì¶”ì •
                    import glob
                    files = glob.glob(os.path.join(self.db_path, "**", "*"), recursive=True)
                    # ëŒ€ëµì ì¸ ì¶”ì • (ì •í™•í•˜ì§€ ì•Šì§€ë§Œ ë¸”ë¡œí‚¹ ì—†ìŒ)
                    estimated_count = max(0, len([f for f in files if os.path.isfile(f)]) // 10)
                except:
                    estimated_count = 0
                    
            return {
                'name': self.kb_name,
                'count': estimated_count,  # ì¶”ì •ê°’ (ë¸”ë¡œí‚¹ ë°©ì§€)
                'path': self.db_path,
                'exists': exists
            }
        
        # ë¹„ë™ê¸°ë¡œ ì‹¤í–‰í•˜ì—¬ ë¸”ë¡œí‚¹ ë°©ì§€
        loop = asyncio.get_event_loop()
        from concurrent.futures import ThreadPoolExecutor
        with ThreadPoolExecutor() as executor:
            return await loop.run_in_executor(executor, get_info_without_chromadb)

