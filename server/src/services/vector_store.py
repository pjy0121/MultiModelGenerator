import chromadb
import os
from typing import List, Dict
from ..core.config import Config

class VectorStore:
    def __init__(self, kb_name: str):
        self.kb_name = kb_name
        self.db_path = Config.get_kb_path(kb_name)
        
        # ì§€ì‹ ë² ì´ìŠ¤ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(self.db_path, exist_ok=True)
        
        self.client = chromadb.PersistentClient(path=self.db_path)
        self.collection = self.client.get_or_create_collection(
            name="spec_documents",
            metadata={"hnsw:space": "cosine"}
        )
    
    def store_chunks(self, chunks: List[Dict]) -> None:
        """ì²­í¬ë“¤ì„ ë²¡í„° DBì— ì €ì¥"""
        print(f"ğŸ’¾ ì§€ì‹ ë² ì´ìŠ¤ '{self.kb_name}'ì— {len(chunks)}ê°œ ì²­í¬ ì €ì¥ ì¤‘...")
        
        # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ìƒˆë¡œ ì €ì¥í•˜ëŠ” ê²½ìš°)
        try:
            self.collection.delete()
            self.collection = self.client.get_or_create_collection(
                name="spec_documents",
                metadata={"hnsw:space": "cosine"}
            )
        except:
            pass
        
        ids = [f"chunk_{chunk['id']}" for chunk in chunks]
        documents = [chunk['content'] for chunk in chunks]
        embeddings = [chunk['embedding'] for chunk in chunks]
        metadatas = [{'length': chunk['length'], 'chunk_id': chunk['id']} for chunk in chunks]
        
        # ë°°ì¹˜ í¬ê¸°ë¡œ ë‚˜ëˆ„ì–´ ì €ì¥ (ChromaDB ì œí•œ)
        batch_size = 100
        for i in range(0, len(chunks), batch_size):
            end_idx = min(i + batch_size, len(chunks))
            
            self.collection.add(
                ids=ids[i:end_idx],
                documents=documents[i:end_idx],
                embeddings=embeddings[i:end_idx],
                metadatas=metadatas[i:end_idx]
            )
        
        print(f"âœ… ì§€ì‹ ë² ì´ìŠ¤ '{self.kb_name}' ì €ì¥ ì™„ë£Œ!")
    
    def search_similar_chunks(self, query: str, top_k: int = None) -> List[str]:
        """ìœ ì‚¬í•œ ì²­í¬ ê²€ìƒ‰"""
        if top_k is None:
            top_k = Config.SEARCH_TOP_K
        
        # ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ ì œí•œ ì ìš©
        if top_k > Config.SEARCH_MAX_TOP_K:
            top_k = Config.SEARCH_MAX_TOP_K
            
        print(f"ğŸ” ì§€ì‹ ë² ì´ìŠ¤ '{self.kb_name}'ì—ì„œ í‚¤ì›Œë“œ '{query}' ê²€ìƒ‰ ì¤‘... (top_k={top_k})")
        
        try:
            # ì»¬ë ‰ì…˜ì´ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
            collection_count = self.collection.count()
            if collection_count == 0:
                print("âŒ ì§€ì‹ ë² ì´ìŠ¤ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                return []
            
            # í¬ê´„ì  ê²€ìƒ‰ ëª¨ë“œê°€ í™œì„±í™”ëœ ê²½ìš°, ë” ë§ì€ ê²°ê³¼ ê²€ìƒ‰
            if Config.SEARCH_ENABLE_COMPREHENSIVE:
                # ì „ì²´ ë¬¸ì„œì˜ 80% ë˜ëŠ” ì„¤ì •ëœ top_k ì¤‘ ë” í° ê°’ ì‚¬ìš©
                comprehensive_top_k = max(top_k, int(collection_count * 0.8))
                actual_top_k = min(comprehensive_top_k, collection_count)
                print(f"ğŸ“– í¬ê´„ì  ê²€ìƒ‰ ëª¨ë“œ: {actual_top_k}ê°œ ì²­í¬ ê²€ìƒ‰ (ì „ì²´ {collection_count}ê°œ ì¤‘)")
            else:
                # ì‹¤ì œ ê²€ìƒ‰í•  ê²°ê³¼ ìˆ˜ ì¡°ì • (ì „ì²´ ì²­í¬ ìˆ˜ë³´ë‹¤ ë§ì„ ìˆ˜ ì—†ìŒ)
                actual_top_k = min(top_k, collection_count)
            
            results = self.collection.query(
                query_texts=[query],
                n_results=actual_top_k,
                include=['documents', 'distances', 'metadatas']
            )
            
            if results['documents'] and results['documents'][0]:
                chunks = results['documents'][0]
                distances = results['distances'][0] if results['distances'] else []
                
                # ìœ ì‚¬ë„ ì ìˆ˜ ê¸°ë°˜ í•„í„°ë§ (ì„¤ì •ëœ ì„ê³„ê°’ ì‚¬ìš©)
                filtered_chunks = []
                for i, (chunk, distance) in enumerate(zip(chunks, distances)):
                    if distance <= Config.SEARCH_SIMILARITY_THRESHOLD:
                        filtered_chunks.append(chunk)
                    # í¬ê´„ì  ê²€ìƒ‰ ëª¨ë“œì—ì„œëŠ” ì¤‘ë‹¨í•˜ì§€ ì•Šê³  ëª¨ë“  ê²°ê³¼ í™•ì¸
                    elif not Config.SEARCH_ENABLE_COMPREHENSIVE:
                        break  # ì¼ë°˜ ëª¨ë“œì—ì„œë§Œ ì¤‘ë‹¨
                
                print(f"ğŸ“š {len(filtered_chunks)}ê°œ ê´€ë ¨ ì²­í¬ ë°œê²¬ (ì´ {len(chunks)}ê°œ ê²€ìƒ‰ ê²°ê³¼ ì¤‘)")
                return filtered_chunks
            else:
                print("âŒ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return []
                
        except Exception as e:
            print(f"âš ï¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []
    
    def get_status(self) -> dict:
        """ì§€ì‹ ë² ì´ìŠ¤ ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        try:
            count = self.collection.count()
            return {
                'exists': True,
                'count': count,
                'path': self.db_path,
                'name': self.kb_name
            }
        except:
            return {
                'exists': False,
                'count': 0,
                'path': self.db_path,
                'name': self.kb_name
            }
