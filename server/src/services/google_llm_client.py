import os
from typing import List, Dict, Any
from .llm_client_interface import LLMClientInterface
from ..core.config import Config

try:
    import google.generativeai as genai
    print(f"âœ… Google AI ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì„±ê³µ")
    print(f"ğŸ” Google AI ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „: {getattr(genai, '__version__', 'Unknown')}")
    print(f"ğŸ” Google AI ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²½ë¡œ: {genai.__file__ if hasattr(genai, '__file__') else 'Unknown'}")
except ImportError as e:
    print(f"âŒ Google AI ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì‹¤íŒ¨: {e}")
    genai = None

class GoogleLLMClient(LLMClientInterface):
    """Google AI Studio API í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self):
        """Google AI API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        self.api_key = Config.GOOGLE_API_KEY
        self.client = None
        
        if genai is None:
            print("âŒ Google AI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ importë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        if self.api_key:
            print(f"ğŸ”‘ Google API Key ë°œê²¬ (ê¸¸ì´: {len(self.api_key)})")
            try:
                genai.configure(api_key=self.api_key)
                self.client = genai
                print("âœ… Google AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
                
                # API í‚¤ ìœ íš¨ì„± í…ŒìŠ¤íŠ¸ëŠ” thinking í•„ë“œ ë²„ê·¸ ë•Œë¬¸ì— ìŠ¤í‚µ
                print("ğŸ§ª API í‚¤ í…ŒìŠ¤íŠ¸ ìŠ¤í‚µ (ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ê·¸ íšŒí”¼)")
                
            except Exception as e:
                print(f"âŒ Google AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                import traceback
                traceback.print_exc()
                self.client = None
        else:
            print("âš ï¸ GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    def is_available(self) -> bool:
        """Google AI API ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        return genai is not None and self.client is not None and self.api_key is not None
    
    def get_available_models(self) -> List[Dict[str, Any]]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ Google AI ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
        print(f"ğŸ” Google AI ëª¨ë¸ ì¡°íšŒ ì‹œì‘ - ì‚¬ìš©ê°€ëŠ¥: {self.is_available()}")
        
        if not self.is_available():
            print("âš ï¸ Google AI í´ë¼ì´ì–¸íŠ¸ê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
            print(f"  - genai ëª¨ë“ˆ: {genai is not None}")
            print(f"  - client: {self.client is not None}")
            print(f"  - api_key: {self.api_key is not None}")
            return []
        
        print("âœ… Google AI í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš© ê°€ëŠ¥, ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì¤‘...")
        
        try:
            # Google AI ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ thinking í•„ë“œ ë²„ê·¸ ë•Œë¬¸ì— í•˜ë“œì½”ë”© ëª¨ë¸ ì‚¬ìš©
            hardcoded_models = [
                "gemini-2.0-flash-exp",
                "gemini-1.5-flash",
                "gemini-1.5-pro",
                "gemini-1.0-pro"
            ]
            
            print(f"ğŸ”„ {len(hardcoded_models)}ê°œì˜ í•˜ë“œì½”ë”©ëœ Google AI ëª¨ë¸ ì‚¬ìš©")
            
            available_models = []
            for model_name in hardcoded_models:
                model_info = {
                    "value": model_name,
                    "label": model_name,
                    "provider": "google",
                    "model_type": model_name,
                    "disabled": False
                }
                available_models.append(model_info)
                print(f"  âœ… ëª¨ë¸ ì¶”ê°€: {model_name}")
            
            print(f"âœ… Google AI: {len(available_models)}ê°œ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            return available_models
            
        except Exception as e:
            print(f"âŒ Google AI ëª¨ë¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            print(f"   ì—ëŸ¬ íƒ€ì…: {type(e).__name__}")
            return []
    
    def chat_completion(self, model: str, messages: List[Dict[str, Any]], **kwargs) -> str:
        """Google AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì±„íŒ… ì™„ì„±"""
        if not self.is_available():
            raise Exception("Google AI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            # messagesë¥¼ í•˜ë‚˜ì˜ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜
            prompt_parts = []
            for message in messages:
                role = message.get("role", "user")
                content = message.get("content", "")
                if role == "system":
                    prompt_parts.append(f"System: {content}")
                elif role == "user":
                    prompt_parts.append(f"User: {content}")
                elif role == "assistant":
                    prompt_parts.append(f"Assistant: {content}")
            
            prompt = "\n".join(prompt_parts)
            return self.generate_response(prompt, model)
            
        except Exception as e:
            raise Exception(f"Google AI ì±„íŒ… ì™„ì„± ì‹¤íŒ¨: {str(e)}")
    
    def generate_response(self, prompt: str, model: str) -> str:
        """Google AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±"""
        if not self.is_available():
            raise Exception("Google AI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            # ëª¨ë¸ ì´ë¦„ì— 'models/' ì ‘ë‘ì‚¬ê°€ ì—†ìœ¼ë©´ ì¶”ê°€
            if not model.startswith('models/'):
                model = f'models/{model}'
            
            # ìƒì„±í˜• ëª¨ë¸ ì´ˆê¸°í™”
            genai_model = genai.GenerativeModel(model)
            
            # ì‘ë‹µ ìƒì„±
            response = genai_model.generate_content(prompt)
            
            if response.text:
                return response.text
            else:
                raise Exception("Google AIì—ì„œ ë¹ˆ ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            raise Exception(f"Google AI ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    def generate_stream_response(self, prompt: str, model: str):
        """Google AIë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±"""
        if not self.is_available():
            raise Exception("Google AI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            # ëª¨ë¸ ì´ë¦„ì— 'models/' ì ‘ë‘ì‚¬ê°€ ì—†ìœ¼ë©´ ì¶”ê°€
            if not model.startswith('models/'):
                model = f'models/{model}'
            
            # ìƒì„±í˜• ëª¨ë¸ ì´ˆê¸°í™”
            genai_model = genai.GenerativeModel(model)
            
            # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
            response = genai_model.generate_content(prompt, stream=True)
            
            for chunk in response:
                if chunk.text:
                    yield chunk.text
                    
        except Exception as e:
            raise Exception(f"Google AI ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    def estimate_tokens(self, text: str, model: str) -> int:
        """í† í° ìˆ˜ ì¶”ì • (ëŒ€ëµì )"""
        if not self.is_available():
            # ê°„ë‹¨í•œ ì¶”ì •: ë‹¨ì–´ ìˆ˜ * 1.3
            return int(len(text.split()) * 1.3)
        
        try:
            # ëª¨ë¸ ì´ë¦„ì— 'models/' ì ‘ë‘ì‚¬ê°€ ì—†ìœ¼ë©´ ì¶”ê°€
            if not model.startswith('models/'):
                model = f'models/{model}'
            
            # Google AIì˜ í† í° ì¹´ìš´íŠ¸ ê¸°ëŠ¥ ì‚¬ìš© (ê°€ëŠ¥í•œ ê²½ìš°)
            genai_model = genai.GenerativeModel(model)
            token_count = genai_model.count_tokens(text)
            return token_count.total_tokens
            
        except Exception:
            # ì‹¤íŒ¨ ì‹œ ê°„ë‹¨í•œ ì¶”ì •
            return int(len(text.split()) * 1.3)