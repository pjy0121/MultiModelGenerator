from openai import OpenAI
from typing import List
from ..core.config import Config

class PerplexityClient:
    def __init__(self):
        try:
            self.client = OpenAI(
                api_key=Config.PERPLEXITY_API_KEY,
                base_url=Config.PERPLEXITY_BASE_URL
            )
        except Exception as e:
            print(f"âš ï¸ Perplexity í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
            print("ğŸ’¡ API í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ê±°ë‚˜ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ì„ í™•ì¸í•˜ì„¸ìš”.")
            raise
    
    def generate_requirements(self, keyword: str, context_chunks: List[str]) -> str:
        """ëª¨ë¸ A: í‚¤ì›Œë“œ ê¸°ë°˜ ìš”êµ¬ì‚¬í•­ ìƒì„±"""
        print(f"ğŸ¤– ìƒì„± ëª¨ë¸: '{keyword}' ìš”êµ¬ì‚¬í•­ ìƒì„± ì¤‘...")
        
        context = "\n\n".join(context_chunks)
        
        prompt = f"""
ë‹¹ì‹ ì€ ê¸°ìˆ  ì‚¬ì–‘ì„œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì œê³µëœ ì‚¬ì–‘ì„œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ '{keyword}'ì— ëŒ€í•œ ìƒì„¸í•œ ìš”êµ¬ì‚¬í•­ ëª©ë¡ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

**ì»¨í…ìŠ¤íŠ¸ (ì‚¬ì–‘ì„œ ë‚´ìš©):**
{context}

**ì‘ì—… ì§€ì¹¨:**
1. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì—ë§Œ ê·¼ê±°í•˜ì—¬ ìš”êµ¬ì‚¬í•­ì„ ë„ì¶œí•˜ì„¸ìš”
2. ê° ìš”êµ¬ì‚¬í•­ì€ êµ¬ì²´ì ì´ê³  ì¸¡ì • ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤
3. 'Figure', 'ê·¸ë¦¼', 'ë„í‘œ', 'ì°¨íŠ¸' ë“± ì‹œê°ì  ìë£Œ ì°¸ì¡°ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
4. ìš”êµ¬ì‚¬í•­ì€ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•˜ì„¸ìš”
5. ì»¨í…ìŠ¤íŠ¸ì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”
6. ê° ìš”êµ¬ì‚¬í•­ì—ëŠ” ê³ ìœ í•œ IDë¥¼ ë¶€ì—¬í•˜ì„¸ìš” (ì˜ˆ: {keyword.upper()[:3]}-001)

**ì¶œë ¥ í¬ë§·:**
ë‹¤ìŒê³¼ ê°™ì€ ë§ˆí¬ë‹¤ìš´ í‘œ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”:

| ID | ìš”êµ¬ì‚¬í•­ (Requirement) | ì¶œì²˜ (Source) | ìƒì„¸ ì„¤ëª… (Notes) |
|---|---|---|---|
| {keyword.upper()[:3]}-001 | [êµ¬ì²´ì ì¸ ìš”êµ¬ì‚¬í•­ ë‚´ìš©] | [ë¬¸ì„œ ì„¹ì…˜ ë²ˆí˜¸ ë˜ëŠ” í˜ì´ì§€] | [ì¶”ê°€ ì„¤ëª… ë˜ëŠ” "-"] |

**í‚¤ì›Œë“œ:** {keyword}

**ìš”êµ¬ì‚¬í•­ í‘œ:**
        """
        
        try:
            response = self.client.chat.completions.create(
                model="sonar-pro",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì •í™•í•œ ê¸°ìˆ  ì‚¬ì–‘ì„œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ì—ë§Œ ê·¼ê±°í•˜ì—¬ ë‹µë³€í•˜ê³ , ì‹œê°ì  ìë£Œ ì°¸ì¡°ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”. ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í‘œ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=2500
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"ìš”êµ¬ì‚¬í•­ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return f"ì˜¤ë¥˜ ë°œìƒ: {e}"
    
    def validate_requirements(self, requirements: str, context_chunks: List[str], round_number: int) -> str:
        """ê²€ì¦ ëª¨ë¸: ìš”êµ¬ì‚¬í•­ ê²€ì¦ ë° ì •ì œ"""
        print(f"ğŸ”¬ ê²€ì¦ ëª¨ë¸ {round_number}: ìš”êµ¬ì‚¬í•­ ê²€ì¦ ë° ì •ì œ ì¤‘...")
        
        context = "\n\n".join(context_chunks)
        
        prompt = f"""
ë‹¹ì‹ ì€ ê¸°ìˆ  ë¬¸ì„œ ê²€ì¦ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. (ê²€ì¦ ë¼ìš´ë“œ: {round_number})

ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ í‘œë¥¼ ê²€í† í•˜ê³  ê²€ì¦í•´ì£¼ì„¸ìš”:

**ì›ë³¸ ì‚¬ì–‘ì„œ ì»¨í…ìŠ¤íŠ¸:**
{context}

**ê²€í† í•  ìš”êµ¬ì‚¬í•­ í‘œ:**
{requirements}

**ê²€ì¦ ì‘ì—…:**
1. ê° ìš”êµ¬ì‚¬í•­ì´ ì›ë³¸ ì‚¬ì–‘ì„œ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì‹¤ì œë¡œ ë„ì¶œ ê°€ëŠ¥í•œì§€ í™•ì¸
2. ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì§€ì›ë˜ì§€ ì•ŠëŠ” ìš”êµ¬ì‚¬í•­ì€ ì œê±°
3. 'Figure', 'ê·¸ë¦¼', 'ë„í‘œ', 'ì°¨íŠ¸' ë“± ì‹œê°ì  ìë£Œ ì°¸ì¡°ê°€ í¬í•¨ëœ ìš”êµ¬ì‚¬í•­ì€ ìˆ˜ì • ë˜ëŠ” ì œê±°
4. ëª¨í˜¸í•˜ê±°ë‚˜ ë¶€ì •í™•í•œ í‘œí˜„ì„ ëª…í™•í•˜ê²Œ ìˆ˜ì •
5. ìš”êµ¬ì‚¬í•­ IDê°€ ë…¼ë¦¬ì ìœ¼ë¡œ ìˆœì„œëŒ€ë¡œ ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
6. ì¶œì²˜(Source) ì •ë³´ê°€ ì •í™•í•œì§€ í™•ì¸
7. ìš”êµ¬ì‚¬í•­ì´ ì´í•´í•˜ê¸° ì‰½ê³  ì¼ëª©ìš”ì—°í•œì§€ í™•ì¸
8. ì¤‘ë³µëœ ìš”êµ¬ì‚¬í•­ì´ ìˆë‹¤ë©´ í†µí•©í•˜ê±°ë‚˜ ì œê±°
9. ìš”êµ¬ì‚¬í•­ì˜ ì™„ì„±ë„ì™€ ì •í™•ì„±ì„ ë†’ì´ì„¸ìš”

**ì¶œë ¥ ì§€ì¹¨:**
- ì›ë˜ ë§ˆí¬ë‹¤ìš´ í‘œ í˜•ì‹ ìœ ì§€
- ê²€ì¦ëœ ìš”êµ¬ì‚¬í•­ë§Œ í¬í•¨
- ê° ìš”êµ¬ì‚¬í•­ì€ ë…ë¦½ì ìœ¼ë¡œ ì´í•´ ê°€ëŠ¥í•´ì•¼ í•¨
- ê¸°ìˆ ì  ìš©ì–´ëŠ” ì •í™•í•˜ê²Œ ì‚¬ìš©
- ID ë²ˆí˜¸ëŠ” ì—°ì†ì ìœ¼ë¡œ ì¬ì •ë ¬
- í’ˆì§ˆì´ í–¥ìƒëœ ìš”êµ¬ì‚¬í•­ í‘œ ì¶œë ¥

**ê²€ì¦ëœ ìš”êµ¬ì‚¬í•­ í‘œ:**
        """
        
        try:
            response = self.client.chat.completions.create(
                model="sonar-pro",
                messages=[
                    {"role": "system", "content": f"ë‹¹ì‹ ì€ ì—„ê²©í•œ ê¸°ìˆ  ë¬¸ì„œ ê²€ì¦ ì „ë¬¸ê°€ì…ë‹ˆë‹¤ (ê²€ì¦ ë¼ìš´ë“œ {round_number}). ì›ë³¸ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì§€ì›ë˜ì§€ ì•ŠëŠ” ë‚´ìš©ê³¼ ì‹œê°ì  ìë£Œ ì°¸ì¡°ëŠ” ë°˜ë“œì‹œ ì œê±°í•˜ì„¸ìš”. ê° ê²€ì¦ ë¼ìš´ë“œë§ˆë‹¤ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ì„¸ìš”. ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í‘œ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.05,
                max_tokens=2500
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"ê²€ì¦ ëª¨ë¸ {round_number} ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return f"ê²€ì¦ ë¼ìš´ë“œ {round_number} ì˜¤ë¥˜ ë°œìƒ: {e}"
    
    def multi_stage_validation(self, keyword: str, context_chunks: List[str], validation_rounds: int = 1) -> str:
        """ë‹¤ë‹¨ê³„ ê²€ì¦ì„ í†µí•œ ìš”êµ¬ì‚¬í•­ ìƒì„±"""
        print(f"ğŸš€ ë‹¤ë‹¨ê³„ ê²€ì¦ ì‹œì‘: {validation_rounds}íšŒ ê²€ì¦")
        print("=" * 50)
        
        # 1ë‹¨ê³„: ì´ˆê¸° ìš”êµ¬ì‚¬í•­ ìƒì„±
        current_requirements = self.generate_requirements(keyword, context_chunks)
        
        if "ì˜¤ë¥˜ ë°œìƒ" in current_requirements:
            return current_requirements
        
        print(f"âœ… ì´ˆê¸° ìƒì„± ì™„ë£Œ")
        
        # 2ë‹¨ê³„: ë‹¤ì¤‘ ê²€ì¦ ë¼ìš´ë“œ
        for round_num in range(1, validation_rounds + 1):
            print(f"\nğŸ”„ ê²€ì¦ ë¼ìš´ë“œ {round_num}/{validation_rounds}")
            
            validated_requirements = self.validate_requirements(
                current_requirements, 
                context_chunks, 
                round_num
            )
            
            if "ì˜¤ë¥˜ ë°œìƒ" in validated_requirements:
                print(f"âš ï¸ ê²€ì¦ ë¼ìš´ë“œ {round_num}ì—ì„œ ì˜¤ë¥˜ ë°œìƒ, ì´ì „ ê²°ê³¼ ì‚¬ìš©")
                break
            
            current_requirements = validated_requirements
            print(f"âœ… ê²€ì¦ ë¼ìš´ë“œ {round_num} ì™„ë£Œ")
        
        print("\n" + "=" * 50)
        print(f"ğŸ‰ {validation_rounds}íšŒ ê²€ì¦ ì™„ë£Œ!")
        
        return current_requirements
    
    def get_available_models(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ Perplexity ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""
        try:
            # Perplexity APIëŠ” í˜„ì¬ models ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì œê³µí•˜ì§€ ì•Šìœ¼ë¯€ë¡œ
            # ì•Œë ¤ì§„ ëª¨ë¸ ëª©ë¡ì„ ë°˜í™˜
            return [
                "sonar-pro",
                "sonar-medium", 
                "sonar-small",
                "llama-3.1-sonar-small-128k-online",
                "llama-3.1-sonar-large-128k-online",
                "llama-3.1-sonar-huge-128k-online"
            ]
        except Exception as e:
            print(f"âš ï¸ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ëª¨ë¸ ëª©ë¡ ë°˜í™˜
            return ["sonar-pro", "sonar-medium"]
