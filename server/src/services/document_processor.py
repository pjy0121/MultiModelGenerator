import PyPDF2
import re
from typing import List, Dict
from sentence_transformers import SentenceTransformer
from ..core.config import VECTOR_DB_CONFIG

class DocumentProcessor:
    def __init__(self, chunk_size: int = None, chunk_overlap: int = None):
        self.chunk_size = chunk_size or VECTOR_DB_CONFIG["chunk_size"]
        self.chunk_overlap = chunk_overlap or VECTOR_DB_CONFIG["chunk_overlap"]
        try:
            self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        except Exception as e:
            print(f"âš ï¸ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("ğŸ’¡ sentence-transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            raise
    
    def extract_text_from_pdf(self, pdf_path: str) -> str:
        """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            with open(pdf_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                text = ""
                
                for page_num, page in enumerate(pdf_reader.pages):
                    page_text = page.extract_text()
                    text += f"\n[Page {page_num + 1}]\n{page_text}\n"
                
                return text
        except Exception as e:
            print(f"PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return ""
    
    def clean_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ì œ"""
        # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
        text = re.sub(r'\s+', ' ', text)
        # íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬
        text = re.sub(r'[^\w\sê°€-í£.,;:()\[\]-]', ' ', text)
        # ë„ˆë¬´ ì§§ì€ ë‹¨ì–´ ì œê±°
        words = text.split()
        words = [word for word in words if len(word) > 1]
        return ' '.join(words)
    
    def semantic_chunking(self, text: str) -> List[Dict[str, any]]:
        """ì˜ë¯¸ë¡ ì  ì²­í‚¹"""
        # ë‹¨ë½ ê¸°ì¤€ìœ¼ë¡œ 1ì°¨ ë¶„í• 
        paragraphs = text.split('\n\n')
        chunks = []
        current_chunk = ""
        chunk_id = 0
        
        for paragraph in paragraphs:
            paragraph = paragraph.strip()
            if not paragraph:
                continue
            
            # ì²­í¬ í¬ê¸° ì²´í¬
            if len(current_chunk) + len(paragraph) > self.chunk_size:
                if current_chunk:
                    chunks.append({
                        'id': chunk_id,
                        'content': self.clean_text(current_chunk),
                        'length': len(current_chunk)
                    })
                    chunk_id += 1
                
                # ì˜¤ë²„ë© ì²˜ë¦¬
                if self.chunk_overlap > 0 and current_chunk:
                    overlap_text = current_chunk[-self.chunk_overlap:]
                    current_chunk = overlap_text + " " + paragraph
                else:
                    current_chunk = paragraph
            else:
                current_chunk += " " + paragraph
        
        # ë§ˆì§€ë§‰ ì²­í¬ ì¶”ê°€
        if current_chunk:
            chunks.append({
                'id': chunk_id,
                'content': self.clean_text(current_chunk),
                'length': len(current_chunk)
            })
        
        return chunks
    
    def generate_embeddings(self, chunks: List[Dict]) -> List[Dict]:
        """ì„ë² ë”© ìƒì„±"""
        print("ì„ë² ë”© ìƒì„± ì¤‘...")
        
        contents = [chunk['content'] for chunk in chunks]
        embeddings = self.embedding_model.encode(contents, show_progress_bar=True)
        
        for i, chunk in enumerate(chunks):
            chunk['embedding'] = embeddings[i].tolist()
        
        return chunks
