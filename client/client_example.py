#!/usr/bin/env python3
"""
MultiModelGenerator Python Client
GET ìš”ì²­ ê¸°ë°˜ ë‹¨ìˆœ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ í´ë¼ì´ì–¸íŠ¸
"""

import requests
import json
import time
import argparse
from typing import Dict, Any
from datetime import datetime
import os


class MultiModelGeneratorClient:
    """MultiModelGenerator Python Client"""
    
    def __init__(self, base_url: str = "http://localhost:5001"):
        """
        í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        
        Args:
            base_url: ì„œë²„ ê¸°ë³¸ URL
        """
        self.base_url = base_url.rstrip('/')
        self.session = requests.Session()
    
    def get_knowledge_bases(self) -> Dict[str, Any]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì§€ì‹ ë² ì´ìŠ¤ ëª©ë¡ ì¡°íšŒ"""
        try:
            response = self.session.get(f"{self.base_url}/knowledge-bases")
            response.raise_for_status()
            return response.json()
        except Exception as e:
            print(f"âŒ ì§€ì‹ ë² ì´ìŠ¤ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    def get_available_models(self) -> Dict[str, Any]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ LLM ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""
        try:
            response = self.session.get(f"{self.base_url}/models/available")
            response.raise_for_status()
            return response.json()
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"models": [], "error": str(e)}
    
    def execute_workflow(
        self,
        knowledge_base: str,
        keyword: str,
        search_intensity: str = "medium",
        generation_nodes: int = 2,
        ensemble_nodes: int = 1,
        validation_nodes: int = 1,
        model_name: str = "gpt-3.5-turbo",
        provider: str = "openai"
    ) -> Dict[str, Any]:
        """
        ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        
        Args:
            knowledge_base: ì‚¬ìš©í•  ì§€ì‹ ë² ì´ìŠ¤ ì´ë¦„
            keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
            search_intensity: ê²€ìƒ‰ ê°•ë„ (low/medium/high)
            generation_nodes: Generation ë ˆì´ì–´ ë…¸ë“œ ê°œìˆ˜
            ensemble_nodes: Ensemble ë ˆì´ì–´ ë…¸ë“œ ê°œìˆ˜  
            validation_nodes: Validation ë ˆì´ì–´ ë…¸ë“œ ê°œìˆ˜
            model_name: ì‚¬ìš©í•  LLM ëª¨ë¸ëª…
            provider: LLM ì œê³µì
            
        Returns:
            Dict: ì‹¤í–‰ ê²°ê³¼
        """
        try:
            print(f"ğŸš€ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹œì‘...")
            print(f"   - ì§€ì‹ ë² ì´ìŠ¤: {knowledge_base}")
            print(f"   - í‚¤ì›Œë“œ: {keyword}")
            print(f"   - ê²€ìƒ‰ ê°•ë„: {search_intensity}")
            print(f"   - ë…¸ë“œ êµ¬ì„±: Gen({generation_nodes}) â†’ Ens({ensemble_nodes}) â†’ Val({validation_nodes})")
            print(f"   - ëª¨ë¸: {provider}/{model_name}")
            print()
            
            # GET íŒŒë¼ë¯¸í„° êµ¬ì„±
            params = {
                "knowledge_base": knowledge_base,
                "keyword": keyword,
                "search_intensity": search_intensity,
                "generation_nodes": generation_nodes,
                "ensemble_nodes": ensemble_nodes,
                "validation_nodes": validation_nodes,
                "model_name": model_name,
                "provider": provider
            }
            
            start_time = time.time()
            
            # GET ìš”ì²­ ì‹¤í–‰
            response = self.session.get(f"{self.base_url}/simple-workflow", params=params)
            response.raise_for_status()
            
            result = response.json()
            execution_time = time.time() - start_time
            
            print(f"âœ… ì›Œí¬í”Œë¡œìš° ì™„ë£Œ (í´ë¼ì´ì–¸íŠ¸ ì¸¡ ì‹¤í–‰ì‹œê°„: {execution_time:.2f}ì´ˆ)")
            print(f"   ì„œë²„ ì¸¡ ì‹¤í–‰ì‹œê°„: {result.get('total_execution_time', 0):.2f}ì´ˆ")
            print()
            
            return result
            
        except requests.exceptions.RequestException as e:
            print(f"âŒ HTTP ìš”ì²­ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": f"HTTP ìš”ì²­ ì‹¤íŒ¨: {str(e)}"}
        except Exception as e:
            print(f"âŒ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    def save_result_to_file(self, result: Dict[str, Any], keyword: str, knowledge_base: str):
        """validation layer ê²°ê³¼ë¥¼ ë¡œì»¬ íŒŒì¼ë¡œ ì €ì¥"""
        if not result.get("success", False):
            print(f"âŒ ì‹¤í–‰ ì‹¤íŒ¨ë¡œ ì¸í•´ íŒŒì¼ ì €ì¥ ë¶ˆê°€: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
            return
        
        # execution_summaryì—ì„œ validation ê²°ê³¼ ì¶”ì¶œ
        summary = result.get("execution_summary", {})
        layer_results = summary.get("layer_results", {})
        validation_output = layer_results.get("validation_output", "")
        
        # ë§Œì•½ validation_outputì´ ë¹„ì–´ìˆë‹¤ë©´ final_resultì—ì„œ ê°€ì ¸ì˜¤ê¸° ì‹œë„
        if not validation_output:
            validation_output = result.get("final_result", "")
            if not validation_output:
                print("âŒ Validation layer ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
        
        # íŒŒì¼ëª… ìƒì„± (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_keyword = "".join(c for c in keyword if c.isalnum() or c in (' ', '-', '_')).rstrip()
        safe_keyword = safe_keyword.replace(' ', '_')
        filename = f"validation_result_{knowledge_base}_{safe_keyword}_{timestamp}.txt"
        
        try:
            # íŒŒì¼ ì €ì¥
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(f"Validation Layer ê²°ê³¼\n")
                f.write(f"===================\n\n")
                f.write(f"ì§€ì‹ ë² ì´ìŠ¤: {knowledge_base}\n")
                f.write(f"ê²€ìƒ‰ í‚¤ì›Œë“œ: {keyword}\n")
                f.write(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"ì´ ì‹¤í–‰ì‹œê°„: {result.get('total_execution_time', 0):.2f}ì´ˆ\n\n")
                f.write("Validation ê²°ê³¼:\n")
                f.write("-" * 50 + "\n")
                f.write(validation_output)
                f.write("\n")
            
            # íŒŒì¼ ê²½ë¡œ ì¶œë ¥
            full_path = os.path.abspath(filename)
            print(f"ğŸ’¾ Validation ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:")
            print(f"   ğŸ“ íŒŒì¼: {filename}")
            print(f"   ğŸ“‚ ê²½ë¡œ: {full_path}")
            print()
            
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")

    def print_result_table(self, result: Dict[str, Any]):
        """ê²°ê³¼ ë§ˆí¬ë‹¤ìš´ í‘œ ì¶œë ¥ - ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ"""
        pass
    
    def print_execution_summary(self, result: Dict[str, Any]):
        """ì‹¤í–‰ ìš”ì•½ ì •ë³´ ì¶œë ¥"""
        if not result.get("success", False):
            return
        
        summary = result.get("execution_summary", {})
        if not summary:
            return
        
        print("ğŸ“Š ì‹¤í–‰ ìš”ì•½:")
        print("-" * 50)
        print(f"ì§€ì‹ ë² ì´ìŠ¤: {summary.get('knowledge_base', 'N/A')}")
        print(f"ê²€ìƒ‰ í‚¤ì›Œë“œ: {summary.get('keyword', 'N/A')}")
        print(f"ê²€ìƒ‰ ê°•ë„: {summary.get('search_intensity', 'N/A')} (top_k: {summary.get('top_k_used', 'N/A')})")
        
        nodes = summary.get('nodes_executed', {})
        print(f"ì‹¤í–‰ëœ ë…¸ë“œ: Gen({nodes.get('generation', 0)}) â†’ Ens({nodes.get('ensemble', 0)}) â†’ Val({nodes.get('validation', 0)})")
        
        model_info = summary.get('model_info', {})
        print(f"ì‚¬ìš© ëª¨ë¸: {model_info.get('provider', 'N/A')}/{model_info.get('model_name', 'N/A')}")
        
        print(f"ì´ ì‹¤í–‰ì‹œê°„: {result.get('total_execution_time', 0):.2f}ì´ˆ")
        print("-" * 50)
        print()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="MultiModelGenerator Python Client")
    parser.add_argument("--server", default="http://localhost:5001", help="ì„œë²„ URL")
    parser.add_argument("--kb", "--knowledge-base", help="ì§€ì‹ ë² ì´ìŠ¤ ì´ë¦„")
    parser.add_argument("--keyword", help="ê²€ìƒ‰ í‚¤ì›Œë“œ")
    parser.add_argument("--intensity", choices=["low", "medium", "high"], default="medium", help="ê²€ìƒ‰ ê°•ë„")
    parser.add_argument("--gen-nodes", type=int, default=2, help="Generation ë…¸ë“œ ê°œìˆ˜")
    parser.add_argument("--ens-nodes", type=int, default=1, help="Ensemble ë…¸ë“œ ê°œìˆ˜")
    parser.add_argument("--val-nodes", type=int, default=1, help="Validation ë…¸ë“œ ê°œìˆ˜")
    parser.add_argument("--model", default="gemini-2.0-flash", help="LLM ëª¨ë¸ëª…")
    parser.add_argument("--provider", choices=["openai", "google"], default="google", help="LLM ì œê³µì")
    parser.add_argument("--list-kb", action="store_true", help="ì§€ì‹ ë² ì´ìŠ¤ ëª©ë¡ë§Œ ì¡°íšŒ")
    parser.add_argument("--list-models", action="store_true", help="ëª¨ë¸ ëª©ë¡ë§Œ ì¡°íšŒ")
    
    args = parser.parse_args()
    
    # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = MultiModelGeneratorClient(args.server)
    
    # ì§€ì‹ ë² ì´ìŠ¤ ëª©ë¡ ì¡°íšŒ
    if args.list_kb:
        print("ğŸ“š ì§€ì‹ ë² ì´ìŠ¤ ëª©ë¡:")
        kb_result = client.get_knowledge_bases()
        if kb_result.get("success", False):
            for kb in kb_result.get("knowledge_bases", []):
                status = "âœ…" if kb.get("exists", False) else "âŒ"
                print(f"   {status} {kb.get('name', 'N/A')} ({kb.get('chunk_count', 0)} chunks)")
        else:
            print(f"   âŒ ì¡°íšŒ ì‹¤íŒ¨: {kb_result.get('error', 'Unknown error')}")
        return
    
    # ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
    if args.list_models:
        print("ğŸ¤– ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:")
        models_result = client.get_available_models()
        for model in models_result.get("models", []):
            status = "âœ…" if not model.get("disabled", True) else "âŒ"
            print(f"   {status} {model.get('provider', 'N/A')}/{model.get('model_type', 'N/A')} - {model.get('label', 'N/A')}")
        return
    
    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ì„ ìœ„í•œ í•„ìˆ˜ ì¸ìˆ˜ í™•ì¸
    if not args.kb or not args.keyword:
        parser.error("ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ì„ ìœ„í•´ì„œëŠ” --kbì™€ --keyword ì¸ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    
    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    result = client.execute_workflow(
        knowledge_base=args.kb,
        keyword=args.keyword,
        search_intensity=args.intensity,
        generation_nodes=args.gen_nodes,
        ensemble_nodes=args.ens_nodes,
        validation_nodes=args.val_nodes,
        model_name=args.model,
        provider=args.provider
    )
    
    # ê²°ê³¼ ì¶œë ¥
    client.print_execution_summary(result)
    client.save_result_to_file(result, args.keyword, args.kb)


if __name__ == "__main__":
    main()